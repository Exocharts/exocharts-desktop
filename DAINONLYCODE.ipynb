{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras/Tensorflow implementation of the Deep Adaptive Input Normalization layer for Time Series Forecasting\n",
    "\n",
    "This notebook contains the Keras/Tensorflow Layer implementation of the Deep Adaptive Input Normalization model  for Time Series Forecasting proposed by Passalis *et al.* ([Deep Adaptive Input Normalization for Time series Forecasting](https://arxiv.org/pdf/1902.07892.pdf)).\n",
    "\n",
    "The authors of the above mentioned paper propose a PyTorch implementation ([PyTorch implementation](https://github.com/passalis/dain)) of the model. A slightly reviewed version (software structure) is here reported. Results obtained by the two implementations are compared through an explicative example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras/Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x250f5c2afa0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaptive_Normalizer_Layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, mode = 'full', input_dim = 2):\n",
    "        super(Adaptive_Normalizer_Layer, self).__init__()\n",
    "        \n",
    "        '''\n",
    "        PARAMETERS\n",
    "        \n",
    "        :param mode: Type of normalization to be performed.\n",
    "                        - 'adaptive_average' performs the adaptive average of the inputs\n",
    "                        - 'adaptive_scale' performs the adaptive z-score normalization of the inputs\n",
    "                        - 'full' (Default) performs the complete normalization process: adaptive_average + adaptive_scale + gating\n",
    "        :param input_dim\n",
    "        '''\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.x = None\n",
    "\n",
    "        self.eps = 1e-8\n",
    "        \n",
    "        initializer = tf.keras.initializers.Identity()\n",
    "        gate_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "        self.linear_1 = tf.keras.layers.Dense(input_dim, kernel_initializer=initializer, use_bias=False)\n",
    "        self.linear_2 = tf.keras.layers.Dense(input_dim, kernel_initializer=initializer, use_bias=False)\n",
    "        self.linear_3 = tf.keras.layers.Dense(input_dim, kernel_initializer=gate_initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Expecting (n_samples, dim, n_feature_vectors)\n",
    "        \n",
    "        def adaptive_avg(inputs):\n",
    "        \n",
    "            avg = tf.keras.backend.mean(inputs, 2)\n",
    "            adaptive_avg = self.linear_1(avg)\n",
    "            adaptive_avg = tf.keras.backend.reshape(adaptive_avg, (tf.shape(inputs)[0].numpy(), tf.shape(inputs)[1].numpy(), 1))\n",
    "            x = inputs - adaptive_avg\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        def adaptive_std(x):\n",
    "        \n",
    "            std = tf.keras.backend.mean(x ** 2, 2)\n",
    "            std = tf.keras.backend.sqrt(std + self.eps)\n",
    "            adaptive_std = self.linear_2(std)\n",
    "            adaptive_std = tf.where(tf.math.less_equal(adaptive_std, self.eps), 1, adaptive_std)\n",
    "            adaptive_std = tf.keras.backend.reshape(adaptive_std, (tf.shape(inputs)[0].numpy(), tf.shape(inputs)[1].numpy(), 1))\n",
    "            x = x / (adaptive_std)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        def gating(x):\n",
    "            \n",
    "            gate = tf.keras.backend.mean(x, 2)\n",
    "            gate = self.linear_3(gate)\n",
    "            gate = tf.math.sigmoid(gate)\n",
    "            gate = tf.keras.backend.reshape(gate, (tf.shape(inputs)[0].numpy(), tf.shape(inputs)[1].numpy(), 1))\n",
    "            x = x * gate\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        if self.mode == None:\n",
    "            pass\n",
    "        \n",
    "        elif self.mode == 'adaptive_average':\n",
    "            self.x = adaptive_avg(inputs)\n",
    "            \n",
    "        elif self.mode == 'adaptive_scale':\n",
    "            self.x = adaptive_avg(inputs)\n",
    "            self.x = adaptive_std(x)\n",
    "            \n",
    "        elif self.mode == 'full':\n",
    "            self.x = adaptive_avg(inputs)\n",
    "            self.x = adaptive_std(self.x)\n",
    "            self.x = gating(self.x)\n",
    "        \n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        return self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dain(col):\n",
    "    example_tensor = tf.constant([[col]])\n",
    "    keras_layer = Adaptive_Normalizer_Layer(input_dim = tf.shape(example_tensor)[1].numpy())\n",
    "    output = np.array(keras_layer(example_tensor)[0][0])\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
