{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408bd305-1a47-49ff-b171-2e231391153b",
   "metadata": {},
   "source": [
    "**DEEPLOB Window size optimisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98403b1a-17be-4a2d-938c-30ca6591e52d",
   "metadata": {},
   "source": [
    "**Reference:** DEEPLOB-XBTUSD.ipynb in exocharts github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f95ffb-3478-4e5d-9bee-d0e0a88c0630",
   "metadata": {},
   "source": [
    "**Description:** Optimising window size parameter for DEEPLOB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e734d2e8-8ae2-4604-b7c5-84c40b80f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe057368",
   "metadata": {},
   "source": [
    "### Data of 2020-09-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd316037",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"bitmex_book_snapshot_25_2020-09-01_XBTUSD.csv\", nrows = 5000)\n",
    "d = d.sort_values(by = 'timestamp')\n",
    "cols =    ['asks['+str(i)+'].price' for i in range(10)] \\\n",
    "        + ['asks['+str(i)+'].amount' for i in range(10)] \\\n",
    "        + ['bids['+str(i)+'].price' for i in range(10)] \\\n",
    "        + ['bids['+str(i)+'].amount' for i in range(10)] \n",
    "d = d[cols]\n",
    "d = d.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac907245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 21:57:59.476990: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs\n",
      "2023-02-07 21:57:59.477239: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, MaxPooling2D, concatenate, LSTM, Reshape, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def get_x_y(df, w = 100, a = 7e-6):\n",
    "    temp = df.copy()\n",
    "    temp[\"mid\"] = (temp['asks[0].price']*temp['bids[0].amount'] + temp['bids[0].price']*temp['asks[0].amount']) / (temp['bids[0].amount'] + temp['asks[0].amount'])\n",
    "    temp[\"mprev\"] = temp.mid.rolling(w).mean()\n",
    "    temp[\"maft\"] = temp.mprev.shift(-1*temp.mprev.isna().sum())\n",
    "    temp = temp.dropna()\n",
    "    temp[\"move\"] = (temp.maft - temp.mid)/temp.mid\n",
    "    temp[\"label\"] = (-(temp.move < -a).astype(int))  + (temp.move > a).astype(int)\n",
    "    return temp.iloc[:, :40], np.array(temp.iloc[:, -1])\n",
    "\n",
    "timestamp_per_sample = 100\n",
    "def reshapex(x):\n",
    "    data_x = np.array(x)\n",
    "    [N, P_x] = data_x.shape\n",
    "    xt = np.empty([(N-timestamp_per_sample+1), timestamp_per_sample, P_x])\n",
    "\n",
    "    for i in range(N-timestamp_per_sample+1):\n",
    "        xt[i] = data_x[i:(i+timestamp_per_sample), :]\n",
    "\n",
    "    xt = xt.reshape(xt.shape + (1,))\n",
    "    return xt\n",
    "    \n",
    "def reshapey(y):\n",
    "    yt = pd.get_dummies(y).values\n",
    "    yt = yt[timestamp_per_sample -1:]\n",
    "    return yt\n",
    "\n",
    "def initiate_DeepLOB_model(lookback_timestep, feature_num, conv_filter_num, inception_num, LSTM_num, leaky_relu_alpha,\n",
    "                          loss, optimizer, metrics):\n",
    "    \n",
    "    input_tensor = Input(shape=(lookback_timestep, feature_num, 1))\n",
    "    conv_layer1 = Conv2D(conv_filter_num, (1,2), strides=(1, 2))(input_tensor)\n",
    "    conv_layer1 =LeakyReLU(alpha=leaky_relu_alpha)(conv_layer1)\n",
    "    conv_layer1 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer1)\n",
    "    conv_first1 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer1)\n",
    "    conv_layer1 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer1)\n",
    "    conv_layer1 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer1)\n",
    "    conv_layer2 = Conv2D(conv_filter_num, (1,2), strides=(1, 2))(conv_layer1)\n",
    "    conv_layer2 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer2)\n",
    "    conv_layer2 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer2)\n",
    "    conv_layer2 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer2)\n",
    "    conv_layer2 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer2)\n",
    "    conv_layer2 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer2)\n",
    "    conv_layer3 = Conv2D(conv_filter_num, (1,10))(conv_layer2)\n",
    "    conv_layer3 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer3)\n",
    "    conv_layer3 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer3)\n",
    "    conv_layer3 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer3)\n",
    "    conv_layer3 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer3)\n",
    "    conv_layer3 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer3)\n",
    "    inception_module1 = Conv2D(inception_num, (1,1), padding='same')(conv_layer3)\n",
    "    inception_module1 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module1)\n",
    "    inception_module1 = Conv2D(inception_num, (3,1), padding='same')(inception_module1)\n",
    "    inception_module1 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module1)\n",
    "    inception_module2 = Conv2D(inception_num, (1,1), padding='same')(conv_layer3)\n",
    "    inception_module2 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module2)\n",
    "    inception_module2 = Conv2D(inception_num, (5,1), padding='same')(inception_module2)\n",
    "    inception_module2 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module2)\n",
    "    inception_module3 = MaxPooling2D((3,1), strides=(1,1), padding='same')(conv_layer3)\n",
    "    inception_module3 = Conv2D(inception_num, (1,1), padding='same')(inception_module3)\n",
    "    inception_module3 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module3)\n",
    "    inception_module_final = concatenate([inception_module1, inception_module2, inception_module3], axis=3)\n",
    "    inception_module_final = Reshape((inception_module_final.shape[1], inception_module_final.shape[3]))(inception_module_final)\n",
    "    LSTM_output = LSTM(LSTM_num)(inception_module_final)\n",
    "    model_output = Dense(3, activation='softmax')(LSTM_output)\n",
    "    DeepLOB_model = Model(inputs=input_tensor, outputs= model_output)  \n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1)\n",
    "    DeepLOB_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return DeepLOB_model\n",
    "\n",
    "#Input param\n",
    "lookback_timestep = 100\n",
    "feature_num = 40\n",
    "\n",
    "#Conv param\n",
    "conv_filter_num = 16\n",
    "\n",
    "#Inception module param\n",
    "inception_num = 32\n",
    "\n",
    "#LSTM param\n",
    "LSTM_num = 64\n",
    "\n",
    "#Activation param\n",
    "leaky_relu_alpha = 0.01\n",
    "\n",
    "#Training params\n",
    "loss = 'categorical_crossentropy'\n",
    "learning_rate = 0.01\n",
    "adam_epsilon = 1\n",
    "optimizer = Adam(learning_rate=learning_rate, epsilon=1)\n",
    "batch_size = 32\n",
    "\n",
    "#Training stopping Criteria\n",
    "metrics = ['accuracy']\n",
    "#stop training when validation accuracy does not improve for 20 epochs\n",
    "stop_epoch_num = 5\n",
    "\n",
    "#max epoch num is not specified in paper, use an arbitrary large number 10000\n",
    "num_epoch = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff4454cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING  50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 21:58:21.008187: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs\n",
      "2023-02-07 21:58:21.009906: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-07 21:58:21.009979: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node-02): /proc/driver/nvidia/version does not exist\n",
      "2023-02-07 21:58:21.013935: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60666, saving model to 50rollingmean.10000nmodel.hdf5\n",
      "121/121 - 14s - loss: 1.0354 - accuracy: 0.5700 - val_loss: 0.9555 - val_accuracy: 0.6067 - 14s/epoch - 114ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.60666\n",
      "121/121 - 11s - loss: 0.9039 - accuracy: 0.6026 - val_loss: 0.8562 - val_accuracy: 0.6067 - 11s/epoch - 88ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.60666\n",
      "121/121 - 10s - loss: 0.8471 - accuracy: 0.6026 - val_loss: 0.8266 - val_accuracy: 0.6067 - 10s/epoch - 83ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.60666\n",
      "121/121 - 10s - loss: 0.8324 - accuracy: 0.6026 - val_loss: 0.8181 - val_accuracy: 0.6067 - 10s/epoch - 83ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.60666\n",
      "121/121 - 10s - loss: 0.8287 - accuracy: 0.6026 - val_loss: 0.8157 - val_accuracy: 0.6067 - 10s/epoch - 82ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.60666\n",
      "121/121 - 10s - loss: 0.8277 - accuracy: 0.6026 - val_loss: 0.8143 - val_accuracy: 0.6067 - 10s/epoch - 82ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  51\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58169, saving model to 51rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.9463 - accuracy: 0.5964 - val_loss: 0.8673 - val_accuracy: 0.5817 - 10s/epoch - 86ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.58169\n",
      "120/120 - 8s - loss: 0.8304 - accuracy: 0.6112 - val_loss: 0.8159 - val_accuracy: 0.5817 - 8s/epoch - 69ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.58169 to 0.61915, saving model to 51rollingmean.10000nmodel.hdf5\n",
      "120/120 - 8s - loss: 0.7947 - accuracy: 0.6112 - val_loss: 0.7545 - val_accuracy: 0.6191 - 8s/epoch - 71ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.61915 to 0.70760, saving model to 51rollingmean.10000nmodel.hdf5\n",
      "120/120 - 8s - loss: 0.7459 - accuracy: 0.6352 - val_loss: 0.7085 - val_accuracy: 0.7076 - 8s/epoch - 70ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.70760\n",
      "120/120 - 8s - loss: 0.7223 - accuracy: 0.6745 - val_loss: 0.6890 - val_accuracy: 0.7066 - 8s/epoch - 71ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.70760\n",
      "120/120 - 9s - loss: 0.7021 - accuracy: 0.6836 - val_loss: 0.6668 - val_accuracy: 0.7066 - 9s/epoch - 72ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.70760\n",
      "120/120 - 8s - loss: 0.6879 - accuracy: 0.6839 - val_loss: 0.6580 - val_accuracy: 0.7045 - 8s/epoch - 71ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.70760\n",
      "120/120 - 8s - loss: 0.6713 - accuracy: 0.6833 - val_loss: 0.6482 - val_accuracy: 0.6972 - 8s/epoch - 70ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.70760\n",
      "120/120 - 9s - loss: 0.6641 - accuracy: 0.7003 - val_loss: 0.6478 - val_accuracy: 0.6878 - 9s/epoch - 72ms/step\n",
      "Epoch 00009: early stopping\n",
      "TRAINING  52\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62292, saving model to 52rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9514 - accuracy: 0.6030 - val_loss: 0.8404 - val_accuracy: 0.6229 - 12s/epoch - 101ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62292\n",
      "120/120 - 10s - loss: 0.8472 - accuracy: 0.6030 - val_loss: 0.8008 - val_accuracy: 0.6229 - 10s/epoch - 82ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62292\n",
      "120/120 - 10s - loss: 0.8318 - accuracy: 0.6030 - val_loss: 0.7909 - val_accuracy: 0.6229 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62292\n",
      "120/120 - 10s - loss: 0.8287 - accuracy: 0.6030 - val_loss: 0.7874 - val_accuracy: 0.6229 - 10s/epoch - 81ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62292\n",
      "120/120 - 10s - loss: 0.8272 - accuracy: 0.6030 - val_loss: 0.7852 - val_accuracy: 0.6229 - 10s/epoch - 81ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.62292\n",
      "120/120 - 10s - loss: 0.8245 - accuracy: 0.6030 - val_loss: 0.7808 - val_accuracy: 0.6229 - 10s/epoch - 82ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  53\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61146, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9257 - accuracy: 0.5989 - val_loss: 0.8369 - val_accuracy: 0.6115 - 12s/epoch - 98ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.61146\n",
      "120/120 - 10s - loss: 0.8155 - accuracy: 0.6078 - val_loss: 0.8169 - val_accuracy: 0.6115 - 10s/epoch - 81ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.61146\n",
      "120/120 - 10s - loss: 0.7966 - accuracy: 0.6078 - val_loss: 0.7914 - val_accuracy: 0.6115 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.61146 to 0.69583, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.7460 - accuracy: 0.6213 - val_loss: 0.7163 - val_accuracy: 0.6958 - 10s/epoch - 83ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.69583 to 0.71146, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6952 - accuracy: 0.6930 - val_loss: 0.6908 - val_accuracy: 0.7115 - 10s/epoch - 82ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.71146 to 0.72812, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6740 - accuracy: 0.7250 - val_loss: 0.6711 - val_accuracy: 0.7281 - 10s/epoch - 82ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.72812 to 0.73958, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6514 - accuracy: 0.7336 - val_loss: 0.6504 - val_accuracy: 0.7396 - 10s/epoch - 82ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.73958 to 0.74167, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6224 - accuracy: 0.7428 - val_loss: 0.6244 - val_accuracy: 0.7417 - 10s/epoch - 82ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.74167 to 0.74687, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6138 - accuracy: 0.7402 - val_loss: 0.6181 - val_accuracy: 0.7469 - 10s/epoch - 82ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.74687 to 0.75729, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6020 - accuracy: 0.7443 - val_loss: 0.6050 - val_accuracy: 0.7573 - 10s/epoch - 82ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75729\n",
      "120/120 - 10s - loss: 0.5874 - accuracy: 0.7433 - val_loss: 0.6092 - val_accuracy: 0.7469 - 10s/epoch - 80ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75729\n",
      "120/120 - 10s - loss: 0.5873 - accuracy: 0.7480 - val_loss: 0.5848 - val_accuracy: 0.7354 - 10s/epoch - 81ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75729\n",
      "120/120 - 10s - loss: 0.5756 - accuracy: 0.7415 - val_loss: 0.5727 - val_accuracy: 0.7281 - 10s/epoch - 80ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75729\n",
      "120/120 - 10s - loss: 0.5649 - accuracy: 0.7501 - val_loss: 0.5935 - val_accuracy: 0.7292 - 10s/epoch - 82ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.75729 to 0.76042, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5624 - accuracy: 0.7485 - val_loss: 0.5635 - val_accuracy: 0.7604 - 10s/epoch - 83ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76042\n",
      "120/120 - 10s - loss: 0.5608 - accuracy: 0.7522 - val_loss: 0.5606 - val_accuracy: 0.7604 - 10s/epoch - 80ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.76042 to 0.76979, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5477 - accuracy: 0.7555 - val_loss: 0.5494 - val_accuracy: 0.7698 - 10s/epoch - 81ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.76979 to 0.77500, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5371 - accuracy: 0.7597 - val_loss: 0.5392 - val_accuracy: 0.7750 - 10s/epoch - 80ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.77500\n",
      "120/120 - 10s - loss: 0.5358 - accuracy: 0.7662 - val_loss: 0.5479 - val_accuracy: 0.7615 - 10s/epoch - 81ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.77500\n",
      "120/120 - 10s - loss: 0.5326 - accuracy: 0.7623 - val_loss: 0.5708 - val_accuracy: 0.7396 - 10s/epoch - 81ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.77500 to 0.77917, saving model to 53rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5306 - accuracy: 0.7673 - val_loss: 0.5214 - val_accuracy: 0.7792 - 10s/epoch - 81ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.77917\n",
      "120/120 - 10s - loss: 0.5235 - accuracy: 0.7649 - val_loss: 0.5473 - val_accuracy: 0.7396 - 10s/epoch - 81ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.77917\n",
      "120/120 - 10s - loss: 0.5218 - accuracy: 0.7665 - val_loss: 0.5115 - val_accuracy: 0.7750 - 10s/epoch - 81ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.77917\n",
      "120/120 - 10s - loss: 0.5093 - accuracy: 0.7709 - val_loss: 0.5299 - val_accuracy: 0.7708 - 10s/epoch - 80ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.77917\n",
      "120/120 - 10s - loss: 0.5067 - accuracy: 0.7678 - val_loss: 0.5207 - val_accuracy: 0.7698 - 10s/epoch - 81ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.77917\n",
      "120/120 - 10s - loss: 0.4934 - accuracy: 0.7766 - val_loss: 0.5021 - val_accuracy: 0.7667 - 10s/epoch - 80ms/step\n",
      "Epoch 00026: early stopping\n",
      "TRAINING  54\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61105, saving model to 54rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9447 - accuracy: 0.6131 - val_loss: 0.8426 - val_accuracy: 0.6111 - 12s/epoch - 99ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.61105\n",
      "120/120 - 10s - loss: 0.8342 - accuracy: 0.6097 - val_loss: 0.8027 - val_accuracy: 0.6111 - 10s/epoch - 81ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.61105\n",
      "120/120 - 10s - loss: 0.8149 - accuracy: 0.6097 - val_loss: 0.7836 - val_accuracy: 0.6111 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.61105\n",
      "120/120 - 10s - loss: 0.7920 - accuracy: 0.6097 - val_loss: 0.7451 - val_accuracy: 0.6111 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.61105 to 0.74140, saving model to 54rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.7357 - accuracy: 0.6517 - val_loss: 0.6710 - val_accuracy: 0.7414 - 10s/epoch - 82ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.74140 to 0.74557, saving model to 54rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6873 - accuracy: 0.7401 - val_loss: 0.6435 - val_accuracy: 0.7456 - 10s/epoch - 83ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74557\n",
      "120/120 - 10s - loss: 0.6717 - accuracy: 0.7404 - val_loss: 0.6330 - val_accuracy: 0.7456 - 10s/epoch - 80ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.74557 to 0.74661, saving model to 54rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6634 - accuracy: 0.7388 - val_loss: 0.6242 - val_accuracy: 0.7466 - 10s/epoch - 81ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74661\n",
      "120/120 - 10s - loss: 0.6551 - accuracy: 0.7424 - val_loss: 0.6164 - val_accuracy: 0.7456 - 10s/epoch - 81ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.74661 to 0.75391, saving model to 54rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6466 - accuracy: 0.7424 - val_loss: 0.6056 - val_accuracy: 0.7539 - 10s/epoch - 81ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75391\n",
      "120/120 - 10s - loss: 0.6308 - accuracy: 0.7432 - val_loss: 0.5912 - val_accuracy: 0.7466 - 10s/epoch - 81ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75391\n",
      "120/120 - 10s - loss: 0.6127 - accuracy: 0.7450 - val_loss: 0.5772 - val_accuracy: 0.7341 - 10s/epoch - 81ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75391\n",
      "120/120 - 10s - loss: 0.5970 - accuracy: 0.7450 - val_loss: 0.5576 - val_accuracy: 0.7466 - 10s/epoch - 79ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.75391 to 0.75912, saving model to 54rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5846 - accuracy: 0.7437 - val_loss: 0.5450 - val_accuracy: 0.7591 - 10s/epoch - 81ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75912\n",
      "120/120 - 10s - loss: 0.5753 - accuracy: 0.7450 - val_loss: 0.5363 - val_accuracy: 0.7560 - 10s/epoch - 81ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75912\n",
      "120/120 - 10s - loss: 0.5922 - accuracy: 0.7404 - val_loss: 0.5617 - val_accuracy: 0.7383 - 10s/epoch - 80ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75912\n",
      "120/120 - 10s - loss: 0.5718 - accuracy: 0.7557 - val_loss: 0.5308 - val_accuracy: 0.7456 - 10s/epoch - 80ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75912\n",
      "120/120 - 10s - loss: 0.5549 - accuracy: 0.7573 - val_loss: 0.5445 - val_accuracy: 0.7424 - 10s/epoch - 81ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75912\n",
      "120/120 - 10s - loss: 0.5476 - accuracy: 0.7591 - val_loss: 0.5340 - val_accuracy: 0.7153 - 10s/epoch - 81ms/step\n",
      "Epoch 00019: early stopping\n",
      "TRAINING  55\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62461, saving model to 55rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9354 - accuracy: 0.6080 - val_loss: 0.8345 - val_accuracy: 0.6246 - 12s/epoch - 103ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62461\n",
      "120/120 - 10s - loss: 0.8293 - accuracy: 0.6080 - val_loss: 0.8080 - val_accuracy: 0.6246 - 10s/epoch - 81ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62461\n",
      "120/120 - 10s - loss: 0.8172 - accuracy: 0.6080 - val_loss: 0.8044 - val_accuracy: 0.6246 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62461\n",
      "120/120 - 10s - loss: 0.8139 - accuracy: 0.6080 - val_loss: 0.8025 - val_accuracy: 0.6246 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62461\n",
      "120/120 - 10s - loss: 0.8118 - accuracy: 0.6080 - val_loss: 0.7995 - val_accuracy: 0.6246 - 10s/epoch - 80ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.62461\n",
      "120/120 - 10s - loss: 0.8064 - accuracy: 0.6080 - val_loss: 0.7899 - val_accuracy: 0.6246 - 10s/epoch - 80ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  56\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61627, saving model to 56rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9581 - accuracy: 0.6036 - val_loss: 0.8542 - val_accuracy: 0.6163 - 12s/epoch - 99ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.61627\n",
      "120/120 - 10s - loss: 0.8396 - accuracy: 0.6127 - val_loss: 0.8068 - val_accuracy: 0.6163 - 10s/epoch - 82ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.61627\n",
      "120/120 - 10s - loss: 0.8190 - accuracy: 0.6127 - val_loss: 0.7940 - val_accuracy: 0.6163 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.61627\n",
      "120/120 - 10s - loss: 0.8136 - accuracy: 0.6127 - val_loss: 0.7886 - val_accuracy: 0.6163 - 10s/epoch - 81ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.61627\n",
      "120/120 - 10s - loss: 0.8099 - accuracy: 0.6127 - val_loss: 0.7826 - val_accuracy: 0.6163 - 10s/epoch - 80ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.61627\n",
      "120/120 - 10s - loss: 0.8006 - accuracy: 0.6127 - val_loss: 0.7666 - val_accuracy: 0.6163 - 10s/epoch - 81ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  57\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63257, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9416 - accuracy: 0.6124 - val_loss: 0.8292 - val_accuracy: 0.6326 - 12s/epoch - 103ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.63257\n",
      "120/120 - 10s - loss: 0.8225 - accuracy: 0.6124 - val_loss: 0.7938 - val_accuracy: 0.6326 - 10s/epoch - 81ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.63257\n",
      "120/120 - 10s - loss: 0.8048 - accuracy: 0.6124 - val_loss: 0.7840 - val_accuracy: 0.6326 - 10s/epoch - 82ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.63257\n",
      "120/120 - 10s - loss: 0.7925 - accuracy: 0.6124 - val_loss: 0.7646 - val_accuracy: 0.6326 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.63257\n",
      "120/120 - 10s - loss: 0.7596 - accuracy: 0.6124 - val_loss: 0.7095 - val_accuracy: 0.6326 - 10s/epoch - 80ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.63257 to 0.70564, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.7019 - accuracy: 0.6575 - val_loss: 0.6640 - val_accuracy: 0.7056 - 10s/epoch - 82ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.70564\n",
      "120/120 - 10s - loss: 0.6809 - accuracy: 0.6852 - val_loss: 0.6560 - val_accuracy: 0.6962 - 10s/epoch - 80ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.70564\n",
      "120/120 - 10s - loss: 0.6655 - accuracy: 0.6936 - val_loss: 0.6382 - val_accuracy: 0.6931 - 10s/epoch - 81ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.70564\n",
      "120/120 - 10s - loss: 0.6490 - accuracy: 0.6993 - val_loss: 0.6190 - val_accuracy: 0.7056 - 10s/epoch - 81ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.70564 to 0.73382, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6243 - accuracy: 0.7403 - val_loss: 0.6038 - val_accuracy: 0.7338 - 10s/epoch - 82ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.73382 to 0.73904, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6070 - accuracy: 0.7473 - val_loss: 0.6027 - val_accuracy: 0.7390 - 10s/epoch - 82ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.73904 to 0.76722, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5863 - accuracy: 0.7562 - val_loss: 0.5681 - val_accuracy: 0.7672 - 10s/epoch - 82ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.76722 to 0.78079, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5721 - accuracy: 0.7599 - val_loss: 0.5413 - val_accuracy: 0.7808 - 10s/epoch - 82ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.78079\n",
      "120/120 - 10s - loss: 0.5561 - accuracy: 0.7659 - val_loss: 0.5365 - val_accuracy: 0.7599 - 10s/epoch - 82ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.78079\n",
      "120/120 - 10s - loss: 0.5460 - accuracy: 0.7674 - val_loss: 0.5289 - val_accuracy: 0.7495 - 10s/epoch - 81ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.78079\n",
      "120/120 - 10s - loss: 0.5258 - accuracy: 0.7729 - val_loss: 0.5017 - val_accuracy: 0.7693 - 10s/epoch - 80ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.78079 to 0.78288, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5308 - accuracy: 0.7656 - val_loss: 0.4846 - val_accuracy: 0.7829 - 10s/epoch - 84ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.78288 to 0.79228, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5048 - accuracy: 0.7739 - val_loss: 0.4763 - val_accuracy: 0.7923 - 10s/epoch - 82ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.79228\n",
      "120/120 - 10s - loss: 0.4985 - accuracy: 0.7776 - val_loss: 0.4885 - val_accuracy: 0.7735 - 10s/epoch - 80ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.79228\n",
      "120/120 - 10s - loss: 0.4791 - accuracy: 0.7927 - val_loss: 0.4677 - val_accuracy: 0.7850 - 10s/epoch - 80ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.79228 to 0.80271, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4843 - accuracy: 0.7831 - val_loss: 0.4420 - val_accuracy: 0.8027 - 10s/epoch - 83ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.80271\n",
      "120/120 - 10s - loss: 0.4643 - accuracy: 0.8011 - val_loss: 0.4615 - val_accuracy: 0.7912 - 10s/epoch - 81ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.80271 to 0.80689, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4662 - accuracy: 0.7930 - val_loss: 0.4287 - val_accuracy: 0.8069 - 10s/epoch - 83ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.80689\n",
      "120/120 - 10s - loss: 0.4473 - accuracy: 0.8048 - val_loss: 0.4656 - val_accuracy: 0.7797 - 10s/epoch - 79ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.80689 to 0.82568, saving model to 57rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4520 - accuracy: 0.8014 - val_loss: 0.4254 - val_accuracy: 0.8257 - 10s/epoch - 83ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.82568\n",
      "120/120 - 9s - loss: 0.4486 - accuracy: 0.8058 - val_loss: 0.4151 - val_accuracy: 0.8142 - 9s/epoch - 79ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.82568\n",
      "120/120 - 10s - loss: 0.4372 - accuracy: 0.8084 - val_loss: 0.4285 - val_accuracy: 0.8038 - 10s/epoch - 81ms/step\n",
      "Epoch 28/10000\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.82568\n",
      "120/120 - 10s - loss: 0.4302 - accuracy: 0.8128 - val_loss: 0.4398 - val_accuracy: 0.8121 - 10s/epoch - 81ms/step\n",
      "Epoch 29/10000\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.82568\n",
      "120/120 - 10s - loss: 0.4252 - accuracy: 0.8207 - val_loss: 0.4087 - val_accuracy: 0.8111 - 10s/epoch - 80ms/step\n",
      "Epoch 30/10000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.82568\n",
      "120/120 - 10s - loss: 0.4284 - accuracy: 0.8207 - val_loss: 0.3917 - val_accuracy: 0.8225 - 10s/epoch - 81ms/step\n",
      "Epoch 00030: early stopping\n",
      "TRAINING  58\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62213, saving model to 58rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9121 - accuracy: 0.6187 - val_loss: 0.7965 - val_accuracy: 0.6221 - 12s/epoch - 99ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62213 to 0.70042, saving model to 58rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.7466 - accuracy: 0.6234 - val_loss: 0.6968 - val_accuracy: 0.7004 - 10s/epoch - 84ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.70042 to 0.71399, saving model to 58rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6802 - accuracy: 0.7226 - val_loss: 0.6720 - val_accuracy: 0.7140 - 10s/epoch - 82ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.71399 to 0.72025, saving model to 58rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6649 - accuracy: 0.7253 - val_loss: 0.6607 - val_accuracy: 0.7203 - 10s/epoch - 83ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.72025 to 0.72129, saving model to 58rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6550 - accuracy: 0.7281 - val_loss: 0.6507 - val_accuracy: 0.7213 - 10s/epoch - 82ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.72129 to 0.72338, saving model to 58rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6453 - accuracy: 0.7334 - val_loss: 0.6411 - val_accuracy: 0.7234 - 10s/epoch - 84ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.72338 to 0.72860, saving model to 58rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6377 - accuracy: 0.7352 - val_loss: 0.6311 - val_accuracy: 0.7286 - 10s/epoch - 82ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.72860 to 0.74322, saving model to 58rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6294 - accuracy: 0.7422 - val_loss: 0.6248 - val_accuracy: 0.7432 - 10s/epoch - 82ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74322\n",
      "120/120 - 10s - loss: 0.6182 - accuracy: 0.7522 - val_loss: 0.6117 - val_accuracy: 0.7432 - 10s/epoch - 80ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.74322 to 0.76827, saving model to 58rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6111 - accuracy: 0.7566 - val_loss: 0.6007 - val_accuracy: 0.7683 - 10s/epoch - 82ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76827\n",
      "120/120 - 10s - loss: 0.6035 - accuracy: 0.7519 - val_loss: 0.6150 - val_accuracy: 0.7547 - 10s/epoch - 80ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76827\n",
      "120/120 - 10s - loss: 0.6046 - accuracy: 0.7553 - val_loss: 0.5934 - val_accuracy: 0.7537 - 10s/epoch - 80ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76827\n",
      "120/120 - 10s - loss: 0.5958 - accuracy: 0.7522 - val_loss: 0.5861 - val_accuracy: 0.7537 - 10s/epoch - 79ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76827\n",
      "120/120 - 10s - loss: 0.5871 - accuracy: 0.7514 - val_loss: 0.5870 - val_accuracy: 0.7484 - 10s/epoch - 80ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76827\n",
      "120/120 - 10s - loss: 0.5748 - accuracy: 0.7574 - val_loss: 0.5680 - val_accuracy: 0.7599 - 10s/epoch - 80ms/step\n",
      "Epoch 00015: early stopping\n",
      "TRAINING  59\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62696, saving model to 59rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9178 - accuracy: 0.6162 - val_loss: 0.8120 - val_accuracy: 0.6270 - 12s/epoch - 100ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62696\n",
      "120/120 - 9s - loss: 0.8022 - accuracy: 0.6204 - val_loss: 0.7840 - val_accuracy: 0.6270 - 9s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62696\n",
      "120/120 - 10s - loss: 0.7817 - accuracy: 0.6204 - val_loss: 0.7613 - val_accuracy: 0.6270 - 10s/epoch - 82ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62696\n",
      "120/120 - 10s - loss: 0.7418 - accuracy: 0.6204 - val_loss: 0.7028 - val_accuracy: 0.6270 - 10s/epoch - 81ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.62696 to 0.70010, saving model to 59rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6850 - accuracy: 0.7061 - val_loss: 0.6729 - val_accuracy: 0.7001 - 10s/epoch - 83ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.70010 to 0.72100, saving model to 59rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6636 - accuracy: 0.7286 - val_loss: 0.6553 - val_accuracy: 0.7210 - 10s/epoch - 84ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.72100 to 0.72936, saving model to 59rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6492 - accuracy: 0.7283 - val_loss: 0.6436 - val_accuracy: 0.7294 - 10s/epoch - 82ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.72936 to 0.73250, saving model to 59rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6361 - accuracy: 0.7362 - val_loss: 0.6300 - val_accuracy: 0.7325 - 10s/epoch - 82ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.73250 to 0.74817, saving model to 59rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6185 - accuracy: 0.7411 - val_loss: 0.6056 - val_accuracy: 0.7482 - 10s/epoch - 84ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.74817 to 0.76280, saving model to 59rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6018 - accuracy: 0.7403 - val_loss: 0.5891 - val_accuracy: 0.7628 - 10s/epoch - 83ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76280\n",
      "120/120 - 10s - loss: 0.5858 - accuracy: 0.7453 - val_loss: 0.5729 - val_accuracy: 0.7618 - 10s/epoch - 80ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76280\n",
      "120/120 - 10s - loss: 0.5803 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7429 - 10s/epoch - 82ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76280\n",
      "120/120 - 10s - loss: 0.5624 - accuracy: 0.7492 - val_loss: 0.5438 - val_accuracy: 0.7597 - 10s/epoch - 81ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76280\n",
      "120/120 - 10s - loss: 0.5488 - accuracy: 0.7563 - val_loss: 0.5435 - val_accuracy: 0.7429 - 10s/epoch - 80ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76280\n",
      "120/120 - 10s - loss: 0.5434 - accuracy: 0.7526 - val_loss: 0.5606 - val_accuracy: 0.7461 - 10s/epoch - 81ms/step\n",
      "Epoch 00015: early stopping\n",
      "TRAINING  60\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61755, saving model to 60rollingmean.10000nmodel.hdf5\n",
      "120/120 - 13s - loss: 0.9024 - accuracy: 0.6200 - val_loss: 0.8161 - val_accuracy: 0.6176 - 13s/epoch - 106ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.61755\n",
      "120/120 - 10s - loss: 0.7996 - accuracy: 0.6249 - val_loss: 0.7939 - val_accuracy: 0.6176 - 10s/epoch - 81ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.61755\n",
      "120/120 - 10s - loss: 0.7913 - accuracy: 0.6249 - val_loss: 0.7894 - val_accuracy: 0.6176 - 10s/epoch - 82ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.61755\n",
      "120/120 - 10s - loss: 0.7875 - accuracy: 0.6249 - val_loss: 0.7841 - val_accuracy: 0.6176 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.61755\n",
      "120/120 - 10s - loss: 0.7794 - accuracy: 0.6249 - val_loss: 0.7709 - val_accuracy: 0.6176 - 10s/epoch - 81ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.61755\n",
      "120/120 - 10s - loss: 0.7523 - accuracy: 0.6249 - val_loss: 0.7181 - val_accuracy: 0.6176 - 10s/epoch - 82ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  61\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62382, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9416 - accuracy: 0.6172 - val_loss: 0.8405 - val_accuracy: 0.6238 - 12s/epoch - 100ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62382\n",
      "120/120 - 10s - loss: 0.8097 - accuracy: 0.6253 - val_loss: 0.7925 - val_accuracy: 0.6238 - 10s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62382\n",
      "120/120 - 10s - loss: 0.7776 - accuracy: 0.6253 - val_loss: 0.7634 - val_accuracy: 0.6238 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.62382 to 0.67503, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.7295 - accuracy: 0.6394 - val_loss: 0.6989 - val_accuracy: 0.6750 - 10s/epoch - 86ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67503 to 0.68130, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6874 - accuracy: 0.6807 - val_loss: 0.6821 - val_accuracy: 0.6813 - 10s/epoch - 83ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.68130 to 0.70115, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6625 - accuracy: 0.7113 - val_loss: 0.6717 - val_accuracy: 0.7011 - 10s/epoch - 83ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.70115\n",
      "120/120 - 10s - loss: 0.6460 - accuracy: 0.7233 - val_loss: 0.6486 - val_accuracy: 0.7001 - 10s/epoch - 81ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.70115 to 0.73250, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6321 - accuracy: 0.7330 - val_loss: 0.6408 - val_accuracy: 0.7325 - 10s/epoch - 84ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73250\n",
      "120/120 - 10s - loss: 0.6230 - accuracy: 0.7367 - val_loss: 0.6246 - val_accuracy: 0.7179 - 10s/epoch - 80ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.73250 to 0.74608, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6027 - accuracy: 0.7482 - val_loss: 0.6041 - val_accuracy: 0.7461 - 10s/epoch - 84ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.74608 to 0.75340, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5813 - accuracy: 0.7555 - val_loss: 0.5798 - val_accuracy: 0.7534 - 10s/epoch - 84ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.75340 to 0.77952, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5594 - accuracy: 0.7607 - val_loss: 0.5567 - val_accuracy: 0.7795 - 10s/epoch - 83ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.77952\n",
      "120/120 - 10s - loss: 0.5457 - accuracy: 0.7589 - val_loss: 0.6148 - val_accuracy: 0.7200 - 10s/epoch - 81ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.77952\n",
      "120/120 - 10s - loss: 0.5247 - accuracy: 0.7701 - val_loss: 0.5185 - val_accuracy: 0.7712 - 10s/epoch - 80ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.77952\n",
      "120/120 - 10s - loss: 0.5057 - accuracy: 0.7728 - val_loss: 0.5208 - val_accuracy: 0.7659 - 10s/epoch - 81ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.77952 to 0.78056, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4934 - accuracy: 0.7782 - val_loss: 0.4967 - val_accuracy: 0.7806 - 10s/epoch - 84ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.78056\n",
      "120/120 - 10s - loss: 0.4815 - accuracy: 0.7858 - val_loss: 0.5191 - val_accuracy: 0.7471 - 10s/epoch - 81ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.78056 to 0.78161, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4861 - accuracy: 0.7782 - val_loss: 0.4837 - val_accuracy: 0.7816 - 10s/epoch - 83ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.78161 to 0.78370, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4685 - accuracy: 0.7976 - val_loss: 0.4995 - val_accuracy: 0.7837 - 10s/epoch - 83ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.78370 to 0.78892, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4672 - accuracy: 0.7916 - val_loss: 0.4841 - val_accuracy: 0.7889 - 10s/epoch - 83ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.78892 to 0.80251, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4556 - accuracy: 0.8020 - val_loss: 0.4945 - val_accuracy: 0.8025 - 10s/epoch - 83ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.80251\n",
      "120/120 - 10s - loss: 0.4621 - accuracy: 0.8010 - val_loss: 0.4771 - val_accuracy: 0.7973 - 10s/epoch - 80ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.80251 to 0.82445, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4470 - accuracy: 0.7999 - val_loss: 0.4361 - val_accuracy: 0.8245 - 10s/epoch - 84ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.82445\n",
      "120/120 - 10s - loss: 0.4357 - accuracy: 0.8193 - val_loss: 0.4320 - val_accuracy: 0.8130 - 10s/epoch - 80ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.82445 to 0.82550, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4313 - accuracy: 0.8201 - val_loss: 0.4481 - val_accuracy: 0.8255 - 10s/epoch - 85ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.82550\n",
      "120/120 - 10s - loss: 0.4364 - accuracy: 0.8115 - val_loss: 0.4234 - val_accuracy: 0.8224 - 10s/epoch - 81ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.82550\n",
      "120/120 - 10s - loss: 0.4312 - accuracy: 0.8162 - val_loss: 0.4286 - val_accuracy: 0.8224 - 10s/epoch - 80ms/step\n",
      "Epoch 28/10000\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.82550 to 0.83490, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4358 - accuracy: 0.8135 - val_loss: 0.4221 - val_accuracy: 0.8349 - 10s/epoch - 83ms/step\n",
      "Epoch 29/10000\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.83490\n",
      "120/120 - 10s - loss: 0.4351 - accuracy: 0.8112 - val_loss: 0.4431 - val_accuracy: 0.7994 - 10s/epoch - 80ms/step\n",
      "Epoch 30/10000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.83490\n",
      "120/120 - 10s - loss: 0.4170 - accuracy: 0.8203 - val_loss: 0.4181 - val_accuracy: 0.8297 - 10s/epoch - 80ms/step\n",
      "Epoch 31/10000\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.83490 to 0.83804, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4004 - accuracy: 0.8282 - val_loss: 0.4401 - val_accuracy: 0.8380 - 10s/epoch - 83ms/step\n",
      "Epoch 32/10000\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.83804\n",
      "120/120 - 9s - loss: 0.4335 - accuracy: 0.8138 - val_loss: 0.4195 - val_accuracy: 0.8349 - 9s/epoch - 78ms/step\n",
      "Epoch 33/10000\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.83804 to 0.85371, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4204 - accuracy: 0.8188 - val_loss: 0.3930 - val_accuracy: 0.8537 - 10s/epoch - 82ms/step\n",
      "Epoch 34/10000\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85371\n",
      "120/120 - 9s - loss: 0.4152 - accuracy: 0.8245 - val_loss: 0.4037 - val_accuracy: 0.8391 - 9s/epoch - 79ms/step\n",
      "Epoch 35/10000\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85371\n",
      "120/120 - 10s - loss: 0.3973 - accuracy: 0.8321 - val_loss: 0.3994 - val_accuracy: 0.8109 - 10s/epoch - 82ms/step\n",
      "Epoch 36/10000\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85371\n",
      "120/120 - 10s - loss: 0.3854 - accuracy: 0.8379 - val_loss: 0.4111 - val_accuracy: 0.8433 - 10s/epoch - 81ms/step\n",
      "Epoch 37/10000\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.85371 to 0.85580, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4096 - accuracy: 0.8177 - val_loss: 0.3780 - val_accuracy: 0.8558 - 10s/epoch - 84ms/step\n",
      "Epoch 38/10000\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.85580 to 0.86102, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.3668 - accuracy: 0.8468 - val_loss: 0.3366 - val_accuracy: 0.8610 - 10s/epoch - 83ms/step\n",
      "Epoch 39/10000\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86102\n",
      "120/120 - 9s - loss: 0.3644 - accuracy: 0.8460 - val_loss: 0.3521 - val_accuracy: 0.8485 - 9s/epoch - 79ms/step\n",
      "Epoch 40/10000\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.86102 to 0.87983, saving model to 61rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.3379 - accuracy: 0.8617 - val_loss: 0.3215 - val_accuracy: 0.8798 - 10s/epoch - 83ms/step\n",
      "Epoch 41/10000\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.87983\n",
      "120/120 - 10s - loss: 0.3690 - accuracy: 0.8478 - val_loss: 0.3440 - val_accuracy: 0.8610 - 10s/epoch - 81ms/step\n",
      "Epoch 42/10000\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.87983\n",
      "120/120 - 10s - loss: 0.3572 - accuracy: 0.8481 - val_loss: 0.3131 - val_accuracy: 0.8798 - 10s/epoch - 81ms/step\n",
      "Epoch 43/10000\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.87983\n",
      "120/120 - 10s - loss: 0.3512 - accuracy: 0.8538 - val_loss: 0.3536 - val_accuracy: 0.8506 - 10s/epoch - 81ms/step\n",
      "Epoch 44/10000\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.87983\n",
      "120/120 - 10s - loss: 0.3398 - accuracy: 0.8564 - val_loss: 0.3757 - val_accuracy: 0.8339 - 10s/epoch - 80ms/step\n",
      "Epoch 45/10000\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.87983\n",
      "120/120 - 10s - loss: 0.3397 - accuracy: 0.8624 - val_loss: 0.3355 - val_accuracy: 0.8631 - 10s/epoch - 80ms/step\n",
      "Epoch 00045: early stopping\n",
      "TRAINING  62\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63808, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9067 - accuracy: 0.6239 - val_loss: 0.8014 - val_accuracy: 0.6381 - 12s/epoch - 104ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.63808\n",
      "120/120 - 10s - loss: 0.7839 - accuracy: 0.6241 - val_loss: 0.7718 - val_accuracy: 0.6381 - 10s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.63808\n",
      "120/120 - 10s - loss: 0.7410 - accuracy: 0.6241 - val_loss: 0.7147 - val_accuracy: 0.6381 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.63808 to 0.71757, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6714 - accuracy: 0.7055 - val_loss: 0.6778 - val_accuracy: 0.7176 - 10s/epoch - 84ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.71757 to 0.74895, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6420 - accuracy: 0.7400 - val_loss: 0.6547 - val_accuracy: 0.7490 - 10s/epoch - 84ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.74895 to 0.75105, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6292 - accuracy: 0.7484 - val_loss: 0.6456 - val_accuracy: 0.7510 - 10s/epoch - 84ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75105\n",
      "120/120 - 10s - loss: 0.6208 - accuracy: 0.7423 - val_loss: 0.6363 - val_accuracy: 0.7479 - 10s/epoch - 80ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75105\n",
      "120/120 - 10s - loss: 0.6120 - accuracy: 0.7481 - val_loss: 0.6275 - val_accuracy: 0.7437 - 10s/epoch - 81ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75105\n",
      "120/120 - 10s - loss: 0.6071 - accuracy: 0.7434 - val_loss: 0.6213 - val_accuracy: 0.7510 - 10s/epoch - 80ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75105\n",
      "120/120 - 10s - loss: 0.5903 - accuracy: 0.7481 - val_loss: 0.6006 - val_accuracy: 0.7500 - 10s/epoch - 79ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.75105 to 0.75209, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5737 - accuracy: 0.7476 - val_loss: 0.5893 - val_accuracy: 0.7521 - 10s/epoch - 83ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.75209 to 0.75314, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5671 - accuracy: 0.7452 - val_loss: 0.5891 - val_accuracy: 0.7531 - 10s/epoch - 82ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75314\n",
      "120/120 - 10s - loss: 0.5572 - accuracy: 0.7518 - val_loss: 0.5806 - val_accuracy: 0.7490 - 10s/epoch - 81ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.75314 to 0.75418, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5494 - accuracy: 0.7502 - val_loss: 0.5664 - val_accuracy: 0.7542 - 10s/epoch - 82ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75418\n",
      "120/120 - 10s - loss: 0.5449 - accuracy: 0.7476 - val_loss: 0.5782 - val_accuracy: 0.7531 - 10s/epoch - 80ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75418\n",
      "120/120 - 10s - loss: 0.5355 - accuracy: 0.7494 - val_loss: 0.5728 - val_accuracy: 0.7364 - 10s/epoch - 80ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.75418 to 0.75523, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5328 - accuracy: 0.7567 - val_loss: 0.5390 - val_accuracy: 0.7552 - 10s/epoch - 83ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75523\n",
      "120/120 - 10s - loss: 0.5245 - accuracy: 0.7539 - val_loss: 0.5615 - val_accuracy: 0.7531 - 10s/epoch - 80ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75523\n",
      "120/120 - 10s - loss: 0.5285 - accuracy: 0.7591 - val_loss: 0.5501 - val_accuracy: 0.7385 - 10s/epoch - 80ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75523\n",
      "120/120 - 10s - loss: 0.5204 - accuracy: 0.7552 - val_loss: 0.5278 - val_accuracy: 0.7500 - 10s/epoch - 81ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.75523 to 0.76569, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5141 - accuracy: 0.7557 - val_loss: 0.5343 - val_accuracy: 0.7657 - 10s/epoch - 82ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.76569 to 0.76674, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5138 - accuracy: 0.7549 - val_loss: 0.5139 - val_accuracy: 0.7667 - 10s/epoch - 84ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.76674 to 0.76987, saving model to 62rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5005 - accuracy: 0.7709 - val_loss: 0.5147 - val_accuracy: 0.7699 - 10s/epoch - 83ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76987\n",
      "120/120 - 10s - loss: 0.5040 - accuracy: 0.7601 - val_loss: 0.5209 - val_accuracy: 0.7688 - 10s/epoch - 81ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76987\n",
      "120/120 - 10s - loss: 0.5025 - accuracy: 0.7586 - val_loss: 0.5001 - val_accuracy: 0.7699 - 10s/epoch - 80ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76987\n",
      "120/120 - 10s - loss: 0.5019 - accuracy: 0.7612 - val_loss: 0.5291 - val_accuracy: 0.7531 - 10s/epoch - 80ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76987\n",
      "120/120 - 10s - loss: 0.4939 - accuracy: 0.7591 - val_loss: 0.5087 - val_accuracy: 0.7688 - 10s/epoch - 79ms/step\n",
      "Epoch 28/10000\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76987\n",
      "120/120 - 10s - loss: 0.4911 - accuracy: 0.7680 - val_loss: 0.4967 - val_accuracy: 0.7469 - 10s/epoch - 80ms/step\n",
      "Epoch 00028: early stopping\n",
      "TRAINING  63\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61611, saving model to 63rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9168 - accuracy: 0.6234 - val_loss: 0.8208 - val_accuracy: 0.6161 - 12s/epoch - 101ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.61611\n",
      "120/120 - 10s - loss: 0.7900 - accuracy: 0.6323 - val_loss: 0.7980 - val_accuracy: 0.6161 - 10s/epoch - 81ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.61611\n",
      "120/120 - 10s - loss: 0.7804 - accuracy: 0.6323 - val_loss: 0.7969 - val_accuracy: 0.6161 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.61611\n",
      "120/120 - 10s - loss: 0.7792 - accuracy: 0.6323 - val_loss: 0.7954 - val_accuracy: 0.6161 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.61611\n",
      "120/120 - 10s - loss: 0.7784 - accuracy: 0.6323 - val_loss: 0.7946 - val_accuracy: 0.6161 - 10s/epoch - 81ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.61611\n",
      "120/120 - 10s - loss: 0.7784 - accuracy: 0.6323 - val_loss: 0.7942 - val_accuracy: 0.6161 - 10s/epoch - 80ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  64\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62408, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.8796 - accuracy: 0.6233 - val_loss: 0.7966 - val_accuracy: 0.6241 - 12s/epoch - 100ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62408\n",
      "120/120 - 10s - loss: 0.7822 - accuracy: 0.6332 - val_loss: 0.7808 - val_accuracy: 0.6241 - 10s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62408\n",
      "120/120 - 10s - loss: 0.7723 - accuracy: 0.6332 - val_loss: 0.7714 - val_accuracy: 0.6241 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62408\n",
      "120/120 - 10s - loss: 0.7578 - accuracy: 0.6332 - val_loss: 0.7478 - val_accuracy: 0.6241 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62408\n",
      "120/120 - 10s - loss: 0.7200 - accuracy: 0.6332 - val_loss: 0.6962 - val_accuracy: 0.6241 - 10s/epoch - 80ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.62408 to 0.74450, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6802 - accuracy: 0.6864 - val_loss: 0.6667 - val_accuracy: 0.7445 - 10s/epoch - 84ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.74450 to 0.75497, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6614 - accuracy: 0.7440 - val_loss: 0.6478 - val_accuracy: 0.7550 - 10s/epoch - 83ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.75497 to 0.75602, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6444 - accuracy: 0.7437 - val_loss: 0.6326 - val_accuracy: 0.7560 - 10s/epoch - 83ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.75602 to 0.75812, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6324 - accuracy: 0.7492 - val_loss: 0.6200 - val_accuracy: 0.7581 - 10s/epoch - 84ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75812\n",
      "120/120 - 10s - loss: 0.6186 - accuracy: 0.7552 - val_loss: 0.6066 - val_accuracy: 0.7581 - 10s/epoch - 80ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75812\n",
      "120/120 - 9s - loss: 0.6048 - accuracy: 0.7592 - val_loss: 0.5897 - val_accuracy: 0.7529 - 9s/epoch - 78ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75812\n",
      "120/120 - 10s - loss: 0.5844 - accuracy: 0.7628 - val_loss: 0.5789 - val_accuracy: 0.7581 - 10s/epoch - 79ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.75812 to 0.76230, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5699 - accuracy: 0.7623 - val_loss: 0.5625 - val_accuracy: 0.7623 - 10s/epoch - 85ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.76230 to 0.78220, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5551 - accuracy: 0.7628 - val_loss: 0.5582 - val_accuracy: 0.7822 - 10s/epoch - 83ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.78220\n",
      "120/120 - 10s - loss: 0.5467 - accuracy: 0.7652 - val_loss: 0.5560 - val_accuracy: 0.7602 - 10s/epoch - 81ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.78220 to 0.79162, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5276 - accuracy: 0.7754 - val_loss: 0.5234 - val_accuracy: 0.7916 - 10s/epoch - 83ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.79162\n",
      "120/120 - 10s - loss: 0.5235 - accuracy: 0.7702 - val_loss: 0.5234 - val_accuracy: 0.7686 - 10s/epoch - 80ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.79162\n",
      "120/120 - 10s - loss: 0.5150 - accuracy: 0.7809 - val_loss: 0.5367 - val_accuracy: 0.7644 - 10s/epoch - 81ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.79162 to 0.80628, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5076 - accuracy: 0.7783 - val_loss: 0.5011 - val_accuracy: 0.8063 - 10s/epoch - 85ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.80628\n",
      "120/120 - 9s - loss: 0.4933 - accuracy: 0.7948 - val_loss: 0.5006 - val_accuracy: 0.7707 - 9s/epoch - 78ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.80628\n",
      "120/120 - 10s - loss: 0.4872 - accuracy: 0.7880 - val_loss: 0.4818 - val_accuracy: 0.8031 - 10s/epoch - 80ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.80628\n",
      "120/120 - 9s - loss: 0.4849 - accuracy: 0.7903 - val_loss: 0.4767 - val_accuracy: 0.7969 - 9s/epoch - 78ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.80628\n",
      "120/120 - 10s - loss: 0.4698 - accuracy: 0.7974 - val_loss: 0.4674 - val_accuracy: 0.7832 - 10s/epoch - 80ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.80628 to 0.82199, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4664 - accuracy: 0.7974 - val_loss: 0.4547 - val_accuracy: 0.8220 - 10s/epoch - 82ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.82199\n",
      "120/120 - 9s - loss: 0.4550 - accuracy: 0.8021 - val_loss: 0.4513 - val_accuracy: 0.8178 - 9s/epoch - 79ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.82199\n",
      "120/120 - 10s - loss: 0.4537 - accuracy: 0.8105 - val_loss: 0.5439 - val_accuracy: 0.7623 - 10s/epoch - 81ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.82199\n",
      "120/120 - 9s - loss: 0.4520 - accuracy: 0.8026 - val_loss: 0.4490 - val_accuracy: 0.8021 - 9s/epoch - 78ms/step\n",
      "Epoch 28/10000\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.82199\n",
      "120/120 - 10s - loss: 0.4370 - accuracy: 0.8089 - val_loss: 0.4370 - val_accuracy: 0.7990 - 10s/epoch - 80ms/step\n",
      "Epoch 29/10000\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.82199 to 0.85236, saving model to 64rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4184 - accuracy: 0.8191 - val_loss: 0.4159 - val_accuracy: 0.8524 - 10s/epoch - 85ms/step\n",
      "Epoch 30/10000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85236\n",
      "120/120 - 9s - loss: 0.4476 - accuracy: 0.8010 - val_loss: 0.4308 - val_accuracy: 0.8220 - 9s/epoch - 78ms/step\n",
      "Epoch 31/10000\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85236\n",
      "120/120 - 10s - loss: 0.4197 - accuracy: 0.8165 - val_loss: 0.4306 - val_accuracy: 0.8220 - 10s/epoch - 79ms/step\n",
      "Epoch 32/10000\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85236\n",
      "120/120 - 9s - loss: 0.4140 - accuracy: 0.8236 - val_loss: 0.4336 - val_accuracy: 0.8115 - 9s/epoch - 79ms/step\n",
      "Epoch 33/10000\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85236\n",
      "120/120 - 10s - loss: 0.4105 - accuracy: 0.8215 - val_loss: 0.4316 - val_accuracy: 0.8042 - 10s/epoch - 80ms/step\n",
      "Epoch 34/10000\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85236\n",
      "120/120 - 10s - loss: 0.4025 - accuracy: 0.8257 - val_loss: 0.4041 - val_accuracy: 0.8283 - 10s/epoch - 79ms/step\n",
      "Epoch 00034: early stopping\n",
      "TRAINING  65\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64712, saving model to 65rollingmean.10000nmodel.hdf5\n",
      "120/120 - 13s - loss: 0.9355 - accuracy: 0.6213 - val_loss: 0.8218 - val_accuracy: 0.6471 - 13s/epoch - 105ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64712\n",
      "120/120 - 10s - loss: 0.8075 - accuracy: 0.6307 - val_loss: 0.7743 - val_accuracy: 0.6471 - 10s/epoch - 81ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64712\n",
      "120/120 - 10s - loss: 0.7815 - accuracy: 0.6307 - val_loss: 0.7578 - val_accuracy: 0.6471 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64712\n",
      "120/120 - 10s - loss: 0.7622 - accuracy: 0.6307 - val_loss: 0.7272 - val_accuracy: 0.6471 - 10s/epoch - 81ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.64712 to 0.68901, saving model to 65rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.7161 - accuracy: 0.6126 - val_loss: 0.6801 - val_accuracy: 0.6890 - 10s/epoch - 85ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.68901 to 0.69843, saving model to 65rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6912 - accuracy: 0.6773 - val_loss: 0.6628 - val_accuracy: 0.6984 - 10s/epoch - 84ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.69843\n",
      "120/120 - 10s - loss: 0.6733 - accuracy: 0.6805 - val_loss: 0.6590 - val_accuracy: 0.6963 - 10s/epoch - 80ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.69843\n",
      "120/120 - 10s - loss: 0.6558 - accuracy: 0.6886 - val_loss: 0.6343 - val_accuracy: 0.6963 - 10s/epoch - 80ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.69843 to 0.73927, saving model to 65rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6328 - accuracy: 0.7085 - val_loss: 0.6026 - val_accuracy: 0.7393 - 10s/epoch - 84ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73927\n",
      "120/120 - 9s - loss: 0.6065 - accuracy: 0.7271 - val_loss: 0.5940 - val_accuracy: 0.7382 - 9s/epoch - 79ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.73927 to 0.75497, saving model to 65rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5921 - accuracy: 0.7352 - val_loss: 0.5691 - val_accuracy: 0.7550 - 10s/epoch - 85ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.75497 to 0.75916, saving model to 65rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5857 - accuracy: 0.7459 - val_loss: 0.5562 - val_accuracy: 0.7592 - 10s/epoch - 83ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75916\n",
      "120/120 - 10s - loss: 0.5763 - accuracy: 0.7438 - val_loss: 0.5713 - val_accuracy: 0.7319 - 10s/epoch - 80ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75916\n",
      "120/120 - 10s - loss: 0.5653 - accuracy: 0.7507 - val_loss: 0.5961 - val_accuracy: 0.6890 - 10s/epoch - 81ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75916\n",
      "120/120 - 10s - loss: 0.5716 - accuracy: 0.7493 - val_loss: 0.5587 - val_accuracy: 0.7414 - 10s/epoch - 80ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.75916 to 0.76545, saving model to 65rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5584 - accuracy: 0.7567 - val_loss: 0.5352 - val_accuracy: 0.7654 - 10s/epoch - 84ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76545\n",
      "120/120 - 10s - loss: 0.5458 - accuracy: 0.7622 - val_loss: 0.5382 - val_accuracy: 0.7518 - 10s/epoch - 80ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76545\n",
      "120/120 - 10s - loss: 0.5650 - accuracy: 0.7281 - val_loss: 0.5583 - val_accuracy: 0.7529 - 10s/epoch - 79ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76545\n",
      "120/120 - 10s - loss: 0.5566 - accuracy: 0.7491 - val_loss: 0.5278 - val_accuracy: 0.7497 - 10s/epoch - 80ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76545\n",
      "120/120 - 10s - loss: 0.5385 - accuracy: 0.7533 - val_loss: 0.5143 - val_accuracy: 0.7518 - 10s/epoch - 80ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76545\n",
      "120/120 - 10s - loss: 0.5137 - accuracy: 0.7601 - val_loss: 0.4885 - val_accuracy: 0.7497 - 10s/epoch - 80ms/step\n",
      "Epoch 00021: early stopping\n",
      "TRAINING  66\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63874, saving model to 66rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9122 - accuracy: 0.6258 - val_loss: 0.7980 - val_accuracy: 0.6387 - 12s/epoch - 101ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.63874\n",
      "120/120 - 10s - loss: 0.7895 - accuracy: 0.6376 - val_loss: 0.7663 - val_accuracy: 0.6387 - 10s/epoch - 81ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.63874\n",
      "120/120 - 10s - loss: 0.7776 - accuracy: 0.6376 - val_loss: 0.7602 - val_accuracy: 0.6387 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.63874\n",
      "120/120 - 10s - loss: 0.7747 - accuracy: 0.6376 - val_loss: 0.7566 - val_accuracy: 0.6387 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.63874\n",
      "120/120 - 10s - loss: 0.7700 - accuracy: 0.6376 - val_loss: 0.7478 - val_accuracy: 0.6387 - 10s/epoch - 80ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.63874\n",
      "120/120 - 10s - loss: 0.7542 - accuracy: 0.6376 - val_loss: 0.7150 - val_accuracy: 0.6387 - 10s/epoch - 81ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  67\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63522, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9112 - accuracy: 0.6417 - val_loss: 0.8095 - val_accuracy: 0.6352 - 12s/epoch - 103ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.63522\n",
      "120/120 - 9s - loss: 0.7798 - accuracy: 0.6417 - val_loss: 0.7759 - val_accuracy: 0.6352 - 9s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.63522\n",
      "120/120 - 10s - loss: 0.7620 - accuracy: 0.6417 - val_loss: 0.7664 - val_accuracy: 0.6352 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.63522\n",
      "120/120 - 10s - loss: 0.7482 - accuracy: 0.6417 - val_loss: 0.7440 - val_accuracy: 0.6352 - 10s/epoch - 79ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.63522 to 0.67820, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6991 - accuracy: 0.6422 - val_loss: 0.6742 - val_accuracy: 0.6782 - 10s/epoch - 84ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.67820 to 0.72327, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6425 - accuracy: 0.7384 - val_loss: 0.6470 - val_accuracy: 0.7233 - 10s/epoch - 84ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.72327\n",
      "120/120 - 10s - loss: 0.6208 - accuracy: 0.7476 - val_loss: 0.6350 - val_accuracy: 0.7212 - 10s/epoch - 79ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.72327\n",
      "120/120 - 10s - loss: 0.6073 - accuracy: 0.7562 - val_loss: 0.6376 - val_accuracy: 0.7191 - 10s/epoch - 80ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.72327 to 0.74214, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5965 - accuracy: 0.7562 - val_loss: 0.6161 - val_accuracy: 0.7421 - 10s/epoch - 85ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74214\n",
      "120/120 - 9s - loss: 0.5825 - accuracy: 0.7581 - val_loss: 0.6066 - val_accuracy: 0.7390 - 9s/epoch - 79ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74214\n",
      "120/120 - 10s - loss: 0.5714 - accuracy: 0.7633 - val_loss: 0.6382 - val_accuracy: 0.7170 - 10s/epoch - 81ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74214\n",
      "120/120 - 10s - loss: 0.5626 - accuracy: 0.7717 - val_loss: 0.5860 - val_accuracy: 0.7421 - 10s/epoch - 80ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.74214 to 0.76730, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5482 - accuracy: 0.7785 - val_loss: 0.5681 - val_accuracy: 0.7673 - 10s/epoch - 84ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76730\n",
      "120/120 - 9s - loss: 0.5392 - accuracy: 0.7790 - val_loss: 0.5624 - val_accuracy: 0.7547 - 9s/epoch - 79ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.76730 to 0.77673, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5339 - accuracy: 0.7790 - val_loss: 0.5393 - val_accuracy: 0.7767 - 10s/epoch - 85ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.77673\n",
      "120/120 - 9s - loss: 0.5274 - accuracy: 0.7714 - val_loss: 0.5538 - val_accuracy: 0.7453 - 9s/epoch - 79ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.77673 to 0.77778, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5209 - accuracy: 0.7822 - val_loss: 0.5334 - val_accuracy: 0.7778 - 10s/epoch - 83ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.77778 to 0.77987, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4972 - accuracy: 0.7942 - val_loss: 0.5224 - val_accuracy: 0.7799 - 10s/epoch - 84ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.77987\n",
      "120/120 - 9s - loss: 0.4928 - accuracy: 0.7937 - val_loss: 0.5050 - val_accuracy: 0.7788 - 9s/epoch - 78ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.77987\n",
      "120/120 - 9s - loss: 0.4836 - accuracy: 0.7942 - val_loss: 0.4923 - val_accuracy: 0.7788 - 9s/epoch - 79ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.77987 to 0.78512, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4757 - accuracy: 0.8010 - val_loss: 0.4908 - val_accuracy: 0.7851 - 10s/epoch - 84ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.78512 to 0.80922, saving model to 67rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4594 - accuracy: 0.8055 - val_loss: 0.4693 - val_accuracy: 0.8092 - 10s/epoch - 82ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.80922\n",
      "120/120 - 9s - loss: 0.4611 - accuracy: 0.8013 - val_loss: 0.4635 - val_accuracy: 0.7998 - 9s/epoch - 78ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.80922\n",
      "120/120 - 9s - loss: 0.4535 - accuracy: 0.8021 - val_loss: 0.4495 - val_accuracy: 0.8029 - 9s/epoch - 79ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.80922\n",
      "120/120 - 9s - loss: 0.4384 - accuracy: 0.8105 - val_loss: 0.5130 - val_accuracy: 0.7862 - 9s/epoch - 79ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.80922\n",
      "120/120 - 10s - loss: 0.4438 - accuracy: 0.8029 - val_loss: 0.4728 - val_accuracy: 0.7872 - 10s/epoch - 80ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.80922\n",
      "120/120 - 10s - loss: 0.4291 - accuracy: 0.8087 - val_loss: 0.4795 - val_accuracy: 0.7914 - 10s/epoch - 80ms/step\n",
      "Epoch 00027: early stopping\n",
      "TRAINING  68\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67296, saving model to 68rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9196 - accuracy: 0.6328 - val_loss: 0.7868 - val_accuracy: 0.6730 - 12s/epoch - 101ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67296\n",
      "120/120 - 10s - loss: 0.7843 - accuracy: 0.6357 - val_loss: 0.7480 - val_accuracy: 0.6730 - 10s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67296\n",
      "120/120 - 10s - loss: 0.7650 - accuracy: 0.6357 - val_loss: 0.7378 - val_accuracy: 0.6730 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76939\n",
      "120/120 - 10s - loss: 0.5955 - accuracy: 0.7467 - val_loss: 0.5841 - val_accuracy: 0.7568 - 10s/epoch - 80ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76939\n",
      "120/120 - 9s - loss: 0.5860 - accuracy: 0.7519 - val_loss: 0.5533 - val_accuracy: 0.7662 - 9s/epoch - 79ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.76939 to 0.77463, saving model to 68rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5722 - accuracy: 0.7569 - val_loss: 0.5287 - val_accuracy: 0.7746 - 10s/epoch - 85ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.77463 to 0.78407, saving model to 68rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5608 - accuracy: 0.7503 - val_loss: 0.5300 - val_accuracy: 0.7841 - 10s/epoch - 83ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.78407\n",
      "120/120 - 9s - loss: 0.5548 - accuracy: 0.7621 - val_loss: 0.5450 - val_accuracy: 0.7442 - 9s/epoch - 79ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.78407\n",
      "120/120 - 10s - loss: 0.5476 - accuracy: 0.7650 - val_loss: 0.5347 - val_accuracy: 0.7600 - 10s/epoch - 79ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.78407 to 0.80189, saving model to 68rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5311 - accuracy: 0.7742 - val_loss: 0.5025 - val_accuracy: 0.8019 - 10s/epoch - 85ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.80189\n",
      "120/120 - 10s - loss: 0.5242 - accuracy: 0.7745 - val_loss: 0.5120 - val_accuracy: 0.7788 - 10s/epoch - 80ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.80189\n",
      "120/120 - 9s - loss: 0.5208 - accuracy: 0.7776 - val_loss: 0.5096 - val_accuracy: 0.7914 - 9s/epoch - 79ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.80189\n",
      "120/120 - 10s - loss: 0.5022 - accuracy: 0.7834 - val_loss: 0.4904 - val_accuracy: 0.8019 - 10s/epoch - 80ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.80189 to 0.80398, saving model to 68rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5082 - accuracy: 0.7808 - val_loss: 0.4833 - val_accuracy: 0.8040 - 10s/epoch - 85ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.80398\n",
      "120/120 - 9s - loss: 0.4993 - accuracy: 0.7810 - val_loss: 0.5009 - val_accuracy: 0.7987 - 9s/epoch - 78ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.80398\n",
      "120/120 - 10s - loss: 0.4932 - accuracy: 0.7857 - val_loss: 0.4901 - val_accuracy: 0.7830 - 10s/epoch - 81ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.80398\n",
      "120/120 - 10s - loss: 0.4872 - accuracy: 0.7907 - val_loss: 0.5058 - val_accuracy: 0.7799 - 10s/epoch - 79ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.80398\n",
      "120/120 - 10s - loss: 0.4884 - accuracy: 0.7844 - val_loss: 0.5172 - val_accuracy: 0.7537 - 10s/epoch - 81ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.80398 to 0.80608, saving model to 68rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4803 - accuracy: 0.7923 - val_loss: 0.4641 - val_accuracy: 0.8061 - 10s/epoch - 85ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.80608\n",
      "120/120 - 10s - loss: 0.4713 - accuracy: 0.7928 - val_loss: 0.5024 - val_accuracy: 0.7966 - 10s/epoch - 81ms/step\n",
      "Epoch 28/10000\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.80608\n",
      "120/120 - 10s - loss: 0.4704 - accuracy: 0.7910 - val_loss: 0.4577 - val_accuracy: 0.8019 - 10s/epoch - 79ms/step\n",
      "Epoch 29/10000\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.80608 to 0.81027, saving model to 68rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4599 - accuracy: 0.8044 - val_loss: 0.4589 - val_accuracy: 0.8103 - 10s/epoch - 84ms/step\n",
      "Epoch 30/10000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.81027\n",
      "120/120 - 10s - loss: 0.4509 - accuracy: 0.8114 - val_loss: 0.4882 - val_accuracy: 0.7904 - 10s/epoch - 80ms/step\n",
      "Epoch 31/10000\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.81027 to 0.82075, saving model to 68rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.4728 - accuracy: 0.7986 - val_loss: 0.4393 - val_accuracy: 0.8208 - 10s/epoch - 85ms/step\n",
      "Epoch 32/10000\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.82075\n",
      "120/120 - 9s - loss: 0.4484 - accuracy: 0.7996 - val_loss: 0.4363 - val_accuracy: 0.8040 - 9s/epoch - 79ms/step\n",
      "Epoch 33/10000\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.82075\n",
      "120/120 - 10s - loss: 0.4414 - accuracy: 0.8088 - val_loss: 0.4734 - val_accuracy: 0.8040 - 10s/epoch - 80ms/step\n",
      "Epoch 34/10000\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.82075\n",
      "120/120 - 10s - loss: 0.4463 - accuracy: 0.8120 - val_loss: 0.4307 - val_accuracy: 0.8134 - 10s/epoch - 80ms/step\n",
      "Epoch 35/10000\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.82075\n",
      "120/120 - 10s - loss: 0.4346 - accuracy: 0.8078 - val_loss: 0.4289 - val_accuracy: 0.8092 - 10s/epoch - 80ms/step\n",
      "Epoch 36/10000\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.82075\n",
      "120/120 - 10s - loss: 0.4286 - accuracy: 0.8148 - val_loss: 0.5166 - val_accuracy: 0.7725 - 10s/epoch - 80ms/step\n",
      "Epoch 00036: early stopping\n",
      "TRAINING  69\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64008, saving model to 69rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.9215 - accuracy: 0.6364 - val_loss: 0.8164 - val_accuracy: 0.6401 - 12s/epoch - 102ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64008\n",
      "120/120 - 10s - loss: 0.7850 - accuracy: 0.6482 - val_loss: 0.7759 - val_accuracy: 0.6401 - 10s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64008\n",
      "120/120 - 10s - loss: 0.7642 - accuracy: 0.6482 - val_loss: 0.7662 - val_accuracy: 0.6401 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64008\n",
      "120/120 - 10s - loss: 0.7588 - accuracy: 0.6482 - val_loss: 0.7628 - val_accuracy: 0.6401 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64008\n",
      "120/120 - 10s - loss: 0.7559 - accuracy: 0.6482 - val_loss: 0.7592 - val_accuracy: 0.6401 - 10s/epoch - 80ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64008\n",
      "120/120 - 10s - loss: 0.7523 - accuracy: 0.6482 - val_loss: 0.7544 - val_accuracy: 0.6401 - 10s/epoch - 81ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  70\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64848, saving model to 70rollingmean.10000nmodel.hdf5\n",
      "120/120 - 12s - loss: 0.8897 - accuracy: 0.6470 - val_loss: 0.7970 - val_accuracy: 0.6485 - 12s/epoch - 101ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64848\n",
      "120/120 - 10s - loss: 0.7721 - accuracy: 0.6501 - val_loss: 0.7663 - val_accuracy: 0.6485 - 10s/epoch - 81ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64848\n",
      "120/120 - 10s - loss: 0.7516 - accuracy: 0.6501 - val_loss: 0.7513 - val_accuracy: 0.6485 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64848\n",
      "120/120 - 10s - loss: 0.7300 - accuracy: 0.6501 - val_loss: 0.7124 - val_accuracy: 0.6485 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.64848 to 0.74711, saving model to 70rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6736 - accuracy: 0.6643 - val_loss: 0.6421 - val_accuracy: 0.7471 - 10s/epoch - 84ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74711\n",
      "120/120 - 10s - loss: 0.6285 - accuracy: 0.7483 - val_loss: 0.6204 - val_accuracy: 0.7471 - 10s/epoch - 80ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.74711 to 0.76600, saving model to 70rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.6143 - accuracy: 0.7472 - val_loss: 0.6003 - val_accuracy: 0.7660 - 10s/epoch - 86ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76600\n",
      "120/120 - 10s - loss: 0.5979 - accuracy: 0.7596 - val_loss: 0.5845 - val_accuracy: 0.7471 - 10s/epoch - 79ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.76600 to 0.76810, saving model to 70rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5844 - accuracy: 0.7593 - val_loss: 0.5686 - val_accuracy: 0.7681 - 10s/epoch - 84ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.76810 to 0.77545, saving model to 70rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5717 - accuracy: 0.7577 - val_loss: 0.5568 - val_accuracy: 0.7754 - 10s/epoch - 84ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.77545\n",
      "120/120 - 9s - loss: 0.5569 - accuracy: 0.7659 - val_loss: 0.5518 - val_accuracy: 0.7587 - 9s/epoch - 79ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.77545 to 0.78489, saving model to 70rollingmean.10000nmodel.hdf5\n",
      "120/120 - 10s - loss: 0.5483 - accuracy: 0.7703 - val_loss: 0.5376 - val_accuracy: 0.7849 - 10s/epoch - 86ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.78489\n",
      "120/120 - 9s - loss: 0.5367 - accuracy: 0.7722 - val_loss: 0.5347 - val_accuracy: 0.7838 - 9s/epoch - 79ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.78489\n",
      "120/120 - 10s - loss: 0.5377 - accuracy: 0.7643 - val_loss: 0.5965 - val_accuracy: 0.7209 - 10s/epoch - 79ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.78489\n",
      "120/120 - 10s - loss: 0.5296 - accuracy: 0.7680 - val_loss: 0.5225 - val_accuracy: 0.7786 - 10s/epoch - 80ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.78489\n",
      "120/120 - 10s - loss: 0.5203 - accuracy: 0.7751 - val_loss: 0.5333 - val_accuracy: 0.7492 - 10s/epoch - 81ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.78489\n",
      "120/120 - 10s - loss: 0.5131 - accuracy: 0.7808 - val_loss: 0.5182 - val_accuracy: 0.7838 - 10s/epoch - 81ms/step\n",
      "Epoch 00017: early stopping\n",
      "TRAINING  71\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65268, saving model to 71rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.9104 - accuracy: 0.6392 - val_loss: 0.7963 - val_accuracy: 0.6527 - 11s/epoch - 91ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65268\n",
      "119/119 - 8s - loss: 0.7712 - accuracy: 0.6520 - val_loss: 0.7608 - val_accuracy: 0.6527 - 8s/epoch - 71ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.65268\n",
      "119/119 - 8s - loss: 0.7530 - accuracy: 0.6520 - val_loss: 0.7535 - val_accuracy: 0.6527 - 8s/epoch - 71ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65268\n",
      "119/119 - 9s - loss: 0.7468 - accuracy: 0.6520 - val_loss: 0.7493 - val_accuracy: 0.6527 - 9s/epoch - 72ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.65268\n",
      "119/119 - 9s - loss: 0.7406 - accuracy: 0.6520 - val_loss: 0.7402 - val_accuracy: 0.6527 - 9s/epoch - 72ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65268\n",
      "119/119 - 8s - loss: 0.7185 - accuracy: 0.6520 - val_loss: 0.7042 - val_accuracy: 0.6527 - 8s/epoch - 70ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  72\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63445, saving model to 72rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.9035 - accuracy: 0.6538 - val_loss: 0.7999 - val_accuracy: 0.6345 - 13s/epoch - 105ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.63445\n",
      "119/119 - 9s - loss: 0.7593 - accuracy: 0.6598 - val_loss: 0.7707 - val_accuracy: 0.6345 - 9s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.63445\n",
      "119/119 - 10s - loss: 0.7456 - accuracy: 0.6598 - val_loss: 0.7665 - val_accuracy: 0.6345 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.63445\n",
      "119/119 - 10s - loss: 0.7422 - accuracy: 0.6598 - val_loss: 0.7627 - val_accuracy: 0.6345 - 10s/epoch - 81ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.63445\n",
      "119/119 - 10s - loss: 0.7384 - accuracy: 0.6598 - val_loss: 0.7588 - val_accuracy: 0.6345 - 10s/epoch - 81ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.63445\n",
      "119/119 - 10s - loss: 0.7292 - accuracy: 0.6598 - val_loss: 0.7407 - val_accuracy: 0.6345 - 10s/epoch - 80ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  73\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65441, saving model to 73rollingmean.10000nmodel.hdf5\n",
      "119/119 - 12s - loss: 0.9018 - accuracy: 0.6520 - val_loss: 0.7847 - val_accuracy: 0.6544 - 12s/epoch - 103ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65441\n",
      "119/119 - 10s - loss: 0.7630 - accuracy: 0.6583 - val_loss: 0.7519 - val_accuracy: 0.6544 - 10s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.65441\n",
      "119/119 - 10s - loss: 0.7483 - accuracy: 0.6583 - val_loss: 0.7450 - val_accuracy: 0.6544 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65441\n",
      "119/119 - 10s - loss: 0.7451 - accuracy: 0.6583 - val_loss: 0.7432 - val_accuracy: 0.6544 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.65441\n",
      "119/119 - 10s - loss: 0.7437 - accuracy: 0.6583 - val_loss: 0.7419 - val_accuracy: 0.6544 - 10s/epoch - 81ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65441\n",
      "119/119 - 9s - loss: 0.7432 - accuracy: 0.6583 - val_loss: 0.7411 - val_accuracy: 0.6544 - 9s/epoch - 79ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  74\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64564, saving model to 74rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.9065 - accuracy: 0.6559 - val_loss: 0.7935 - val_accuracy: 0.6456 - 13s/epoch - 106ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64564\n",
      "119/119 - 10s - loss: 0.7616 - accuracy: 0.6630 - val_loss: 0.7522 - val_accuracy: 0.6456 - 10s/epoch - 83ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64564\n",
      "119/119 - 10s - loss: 0.7443 - accuracy: 0.6630 - val_loss: 0.7407 - val_accuracy: 0.6456 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64564\n",
      "119/119 - 10s - loss: 0.7404 - accuracy: 0.6630 - val_loss: 0.7368 - val_accuracy: 0.6456 - 10s/epoch - 82ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64564\n",
      "119/119 - 10s - loss: 0.7397 - accuracy: 0.6630 - val_loss: 0.7350 - val_accuracy: 0.6456 - 10s/epoch - 82ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.64564\n",
      "119/119 - 10s - loss: 0.7377 - accuracy: 0.6630 - val_loss: 0.7329 - val_accuracy: 0.6456 - 10s/epoch - 80ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  75\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64774, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.9075 - accuracy: 0.6625 - val_loss: 0.8017 - val_accuracy: 0.6477 - 13s/epoch - 107ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64774\n",
      "119/119 - 11s - loss: 0.7559 - accuracy: 0.6641 - val_loss: 0.7596 - val_accuracy: 0.6477 - 11s/epoch - 90ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64774\n",
      "119/119 - 10s - loss: 0.7320 - accuracy: 0.6641 - val_loss: 0.7486 - val_accuracy: 0.6477 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64774\n",
      "119/119 - 10s - loss: 0.7163 - accuracy: 0.6641 - val_loss: 0.7239 - val_accuracy: 0.6477 - 10s/epoch - 81ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64774\n",
      "119/119 - 10s - loss: 0.6599 - accuracy: 0.6641 - val_loss: 0.6506 - val_accuracy: 0.6477 - 10s/epoch - 81ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.64774 to 0.72660, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.5979 - accuracy: 0.7459 - val_loss: 0.6268 - val_accuracy: 0.7266 - 11s/epoch - 91ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.72660 to 0.72766, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5789 - accuracy: 0.7612 - val_loss: 0.6137 - val_accuracy: 0.7277 - 10s/epoch - 85ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.72766 to 0.73922, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5677 - accuracy: 0.7612 - val_loss: 0.6039 - val_accuracy: 0.7392 - 10s/epoch - 87ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73922\n",
      "119/119 - 9s - loss: 0.5583 - accuracy: 0.7688 - val_loss: 0.5924 - val_accuracy: 0.7308 - 9s/epoch - 80ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.73922 to 0.74869, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5489 - accuracy: 0.7783 - val_loss: 0.5825 - val_accuracy: 0.7487 - 10s/epoch - 86ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74869\n",
      "119/119 - 9s - loss: 0.5382 - accuracy: 0.7772 - val_loss: 0.5679 - val_accuracy: 0.7424 - 9s/epoch - 78ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74869\n",
      "119/119 - 10s - loss: 0.5264 - accuracy: 0.7741 - val_loss: 0.5574 - val_accuracy: 0.7371 - 10s/epoch - 80ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.74869 to 0.75499, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5188 - accuracy: 0.7780 - val_loss: 0.5415 - val_accuracy: 0.7550 - 10s/epoch - 87ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.75499 to 0.75710, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5069 - accuracy: 0.7846 - val_loss: 0.5318 - val_accuracy: 0.7571 - 10s/epoch - 85ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.75710 to 0.77603, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4999 - accuracy: 0.7851 - val_loss: 0.5206 - val_accuracy: 0.7760 - 10s/epoch - 85ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.77603\n",
      "119/119 - 9s - loss: 0.4915 - accuracy: 0.7875 - val_loss: 0.5264 - val_accuracy: 0.7508 - 9s/epoch - 79ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.77603 to 0.78970, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4816 - accuracy: 0.7920 - val_loss: 0.5025 - val_accuracy: 0.7897 - 10s/epoch - 85ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.78970\n",
      "119/119 - 9s - loss: 0.4822 - accuracy: 0.7941 - val_loss: 0.5302 - val_accuracy: 0.7319 - 9s/epoch - 79ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.78970\n",
      "119/119 - 10s - loss: 0.4680 - accuracy: 0.7988 - val_loss: 0.4931 - val_accuracy: 0.7750 - 10s/epoch - 80ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.78970 to 0.79390, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4657 - accuracy: 0.8012 - val_loss: 0.4807 - val_accuracy: 0.7939 - 10s/epoch - 86ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.79390 to 0.80862, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4626 - accuracy: 0.8030 - val_loss: 0.4749 - val_accuracy: 0.8086 - 10s/epoch - 85ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.80862\n",
      "119/119 - 9s - loss: 0.4557 - accuracy: 0.8130 - val_loss: 0.4717 - val_accuracy: 0.8086 - 9s/epoch - 80ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.80862\n",
      "119/119 - 10s - loss: 0.4548 - accuracy: 0.8033 - val_loss: 0.4756 - val_accuracy: 0.7834 - 10s/epoch - 80ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.80862\n",
      "119/119 - 10s - loss: 0.4520 - accuracy: 0.8041 - val_loss: 0.4819 - val_accuracy: 0.7729 - 10s/epoch - 80ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.80862\n",
      "119/119 - 10s - loss: 0.4447 - accuracy: 0.8067 - val_loss: 0.4605 - val_accuracy: 0.7939 - 10s/epoch - 82ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.80862 to 0.81388, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4403 - accuracy: 0.8164 - val_loss: 0.4509 - val_accuracy: 0.8139 - 10s/epoch - 85ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.81388\n",
      "119/119 - 10s - loss: 0.4394 - accuracy: 0.8190 - val_loss: 0.4582 - val_accuracy: 0.7876 - 10s/epoch - 80ms/step\n",
      "Epoch 28/10000\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.81388\n",
      "119/119 - 9s - loss: 0.4309 - accuracy: 0.8154 - val_loss: 0.4536 - val_accuracy: 0.8034 - 9s/epoch - 78ms/step\n",
      "Epoch 29/10000\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.81388\n",
      "119/119 - 9s - loss: 0.4284 - accuracy: 0.8156 - val_loss: 0.4607 - val_accuracy: 0.7876 - 9s/epoch - 80ms/step\n",
      "Epoch 30/10000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.81388\n",
      "119/119 - 9s - loss: 0.4289 - accuracy: 0.8130 - val_loss: 0.4485 - val_accuracy: 0.8023 - 9s/epoch - 79ms/step\n",
      "Epoch 31/10000\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.81388 to 0.81493, saving model to 75rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4160 - accuracy: 0.8211 - val_loss: 0.4360 - val_accuracy: 0.8149 - 10s/epoch - 87ms/step\n",
      "Epoch 32/10000\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.81493\n",
      "119/119 - 10s - loss: 0.4138 - accuracy: 0.8209 - val_loss: 0.4504 - val_accuracy: 0.8002 - 10s/epoch - 80ms/step\n",
      "Epoch 33/10000\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.81493\n",
      "119/119 - 9s - loss: 0.4301 - accuracy: 0.8125 - val_loss: 0.4553 - val_accuracy: 0.7697 - 9s/epoch - 79ms/step\n",
      "Epoch 34/10000\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.81493\n",
      "119/119 - 9s - loss: 0.4122 - accuracy: 0.8211 - val_loss: 0.4370 - val_accuracy: 0.7823 - 9s/epoch - 80ms/step\n",
      "Epoch 35/10000\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.81493\n",
      "119/119 - 10s - loss: 0.4039 - accuracy: 0.8209 - val_loss: 0.4258 - val_accuracy: 0.8044 - 10s/epoch - 80ms/step\n",
      "Epoch 36/10000\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.81493\n",
      "119/119 - 9s - loss: 0.3968 - accuracy: 0.8256 - val_loss: 0.4083 - val_accuracy: 0.8149 - 9s/epoch - 79ms/step\n",
      "Epoch 00036: early stopping\n",
      "TRAINING  76\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67508, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8944 - accuracy: 0.6482 - val_loss: 0.7537 - val_accuracy: 0.6751 - 13s/epoch - 106ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67508\n",
      "119/119 - 10s - loss: 0.7548 - accuracy: 0.6592 - val_loss: 0.7136 - val_accuracy: 0.6751 - 10s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67508\n",
      "119/119 - 10s - loss: 0.7384 - accuracy: 0.6592 - val_loss: 0.7024 - val_accuracy: 0.6751 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67508\n",
      "119/119 - 10s - loss: 0.7261 - accuracy: 0.6592 - val_loss: 0.6801 - val_accuracy: 0.6751 - 10s/epoch - 81ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67508\n",
      "119/119 - 10s - loss: 0.6821 - accuracy: 0.6487 - val_loss: 0.6225 - val_accuracy: 0.6393 - 10s/epoch - 81ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.67508 to 0.70873, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.6427 - accuracy: 0.6634 - val_loss: 0.6020 - val_accuracy: 0.7087 - 10s/epoch - 87ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.70873 to 0.71083, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.6195 - accuracy: 0.6889 - val_loss: 0.5742 - val_accuracy: 0.7108 - 10s/epoch - 86ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.71083 to 0.76972, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5833 - accuracy: 0.7497 - val_loss: 0.5346 - val_accuracy: 0.7697 - 10s/epoch - 87ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76972\n",
      "119/119 - 10s - loss: 0.5537 - accuracy: 0.7676 - val_loss: 0.5420 - val_accuracy: 0.7287 - 10s/epoch - 80ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.76972 to 0.78128, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5351 - accuracy: 0.7753 - val_loss: 0.4903 - val_accuracy: 0.7813 - 10s/epoch - 87ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.78128 to 0.79600, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5080 - accuracy: 0.7839 - val_loss: 0.4806 - val_accuracy: 0.7960 - 10s/epoch - 87ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79600\n",
      "119/119 - 10s - loss: 0.4976 - accuracy: 0.7926 - val_loss: 0.4834 - val_accuracy: 0.7729 - 10s/epoch - 81ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.79600 to 0.81073, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4909 - accuracy: 0.7858 - val_loss: 0.4414 - val_accuracy: 0.8107 - 10s/epoch - 88ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.81073\n",
      "119/119 - 10s - loss: 0.4873 - accuracy: 0.7924 - val_loss: 0.4453 - val_accuracy: 0.7865 - 10s/epoch - 80ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.81073 to 0.81809, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4549 - accuracy: 0.8032 - val_loss: 0.4112 - val_accuracy: 0.8181 - 10s/epoch - 88ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.81809\n",
      "119/119 - 9s - loss: 0.4590 - accuracy: 0.8026 - val_loss: 0.4230 - val_accuracy: 0.8097 - 9s/epoch - 79ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.81809\n",
      "119/119 - 10s - loss: 0.4366 - accuracy: 0.8166 - val_loss: 0.4052 - val_accuracy: 0.8107 - 10s/epoch - 81ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.81809 to 0.82545, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4263 - accuracy: 0.8174 - val_loss: 0.3855 - val_accuracy: 0.8254 - 10s/epoch - 87ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82545\n",
      "119/119 - 10s - loss: 0.4448 - accuracy: 0.8079 - val_loss: 0.4201 - val_accuracy: 0.8202 - 10s/epoch - 80ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.82545 to 0.84122, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4221 - accuracy: 0.8200 - val_loss: 0.3889 - val_accuracy: 0.8412 - 10s/epoch - 87ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84122\n",
      "119/119 - 10s - loss: 0.4044 - accuracy: 0.8326 - val_loss: 0.3660 - val_accuracy: 0.8412 - 10s/epoch - 81ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84122\n",
      "119/119 - 10s - loss: 0.4069 - accuracy: 0.8321 - val_loss: 0.4144 - val_accuracy: 0.8233 - 10s/epoch - 80ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84122\n",
      "119/119 - 10s - loss: 0.4225 - accuracy: 0.8237 - val_loss: 0.3980 - val_accuracy: 0.8297 - 10s/epoch - 80ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84122\n",
      "119/119 - 10s - loss: 0.4043 - accuracy: 0.8311 - val_loss: 0.3782 - val_accuracy: 0.8402 - 10s/epoch - 80ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.84122 to 0.84753, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.3966 - accuracy: 0.8405 - val_loss: 0.3421 - val_accuracy: 0.8475 - 10s/epoch - 86ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.84753 to 0.86961, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.3972 - accuracy: 0.8321 - val_loss: 0.3427 - val_accuracy: 0.8696 - 10s/epoch - 86ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86961\n",
      "119/119 - 10s - loss: 0.3777 - accuracy: 0.8445 - val_loss: 0.3537 - val_accuracy: 0.8549 - 10s/epoch - 81ms/step\n",
      "Epoch 28/10000\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86961\n",
      "119/119 - 10s - loss: 0.3893 - accuracy: 0.8408 - val_loss: 0.3491 - val_accuracy: 0.8601 - 10s/epoch - 80ms/step\n",
      "Epoch 29/10000\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.86961 to 0.87487, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.3794 - accuracy: 0.8445 - val_loss: 0.3208 - val_accuracy: 0.8749 - 10s/epoch - 87ms/step\n",
      "Epoch 30/10000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.87487\n",
      "119/119 - 9s - loss: 0.3601 - accuracy: 0.8466 - val_loss: 0.3147 - val_accuracy: 0.8644 - 9s/epoch - 79ms/step\n",
      "Epoch 31/10000\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.87487\n",
      "119/119 - 10s - loss: 0.3641 - accuracy: 0.8484 - val_loss: 0.3173 - val_accuracy: 0.8717 - 10s/epoch - 80ms/step\n",
      "Epoch 32/10000\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.87487 to 0.88013, saving model to 76rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.3657 - accuracy: 0.8453 - val_loss: 0.3301 - val_accuracy: 0.8801 - 10s/epoch - 87ms/step\n",
      "Epoch 33/10000\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.88013\n",
      "119/119 - 10s - loss: 0.3698 - accuracy: 0.8445 - val_loss: 0.3195 - val_accuracy: 0.8623 - 10s/epoch - 80ms/step\n",
      "Epoch 34/10000\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.88013\n",
      "119/119 - 9s - loss: 0.3610 - accuracy: 0.8539 - val_loss: 0.3073 - val_accuracy: 0.8686 - 9s/epoch - 80ms/step\n",
      "Epoch 35/10000\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.88013\n",
      "119/119 - 10s - loss: 0.3628 - accuracy: 0.8495 - val_loss: 0.3631 - val_accuracy: 0.8318 - 10s/epoch - 80ms/step\n",
      "Epoch 36/10000\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.88013\n",
      "119/119 - 10s - loss: 0.3430 - accuracy: 0.8611 - val_loss: 0.2977 - val_accuracy: 0.8738 - 10s/epoch - 81ms/step\n",
      "Epoch 37/10000\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.88013\n",
      "119/119 - 9s - loss: 0.3558 - accuracy: 0.8418 - val_loss: 0.3261 - val_accuracy: 0.8549 - 9s/epoch - 79ms/step\n",
      "Epoch 00037: early stopping\n",
      "TRAINING  77\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66632, saving model to 77rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8646 - accuracy: 0.6639 - val_loss: 0.7587 - val_accuracy: 0.6663 - 13s/epoch - 112ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66632\n",
      "119/119 - 9s - loss: 0.7353 - accuracy: 0.6639 - val_loss: 0.7268 - val_accuracy: 0.6663 - 9s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66632\n",
      "119/119 - 9s - loss: 0.6968 - accuracy: 0.6639 - val_loss: 0.6732 - val_accuracy: 0.6663 - 9s/epoch - 79ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.66632 to 0.69368, saving model to 77rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.6241 - accuracy: 0.6786 - val_loss: 0.6284 - val_accuracy: 0.6937 - 11s/epoch - 92ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.69368 to 0.74105, saving model to 77rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.6007 - accuracy: 0.7202 - val_loss: 0.6127 - val_accuracy: 0.7411 - 11s/epoch - 90ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.74105 to 0.77158, saving model to 77rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.5864 - accuracy: 0.7518 - val_loss: 0.5959 - val_accuracy: 0.7716 - 11s/epoch - 92ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77158\n",
      "119/119 - 9s - loss: 0.5655 - accuracy: 0.7644 - val_loss: 0.5737 - val_accuracy: 0.7484 - 9s/epoch - 77ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77158\n",
      "119/119 - 10s - loss: 0.5572 - accuracy: 0.7623 - val_loss: 0.5794 - val_accuracy: 0.7263 - 10s/epoch - 80ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.77158\n",
      "119/119 - 9s - loss: 0.5320 - accuracy: 0.7697 - val_loss: 0.5402 - val_accuracy: 0.7642 - 9s/epoch - 79ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.77158\n",
      "119/119 - 10s - loss: 0.5095 - accuracy: 0.7718 - val_loss: 0.5331 - val_accuracy: 0.7505 - 10s/epoch - 81ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.77158 to 0.80316, saving model to 77rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.5009 - accuracy: 0.7805 - val_loss: 0.5050 - val_accuracy: 0.8032 - 11s/epoch - 90ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80316\n",
      "119/119 - 9s - loss: 0.4846 - accuracy: 0.7831 - val_loss: 0.4996 - val_accuracy: 0.7705 - 9s/epoch - 79ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.80316 to 0.80947, saving model to 77rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4790 - accuracy: 0.7836 - val_loss: 0.4795 - val_accuracy: 0.8095 - 11s/epoch - 92ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.80947\n",
      "119/119 - 9s - loss: 0.4535 - accuracy: 0.7915 - val_loss: 0.4618 - val_accuracy: 0.8000 - 9s/epoch - 80ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.80947 to 0.82421, saving model to 77rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4541 - accuracy: 0.7934 - val_loss: 0.4605 - val_accuracy: 0.8242 - 11s/epoch - 91ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82421\n",
      "119/119 - 9s - loss: 0.4398 - accuracy: 0.8055 - val_loss: 0.5125 - val_accuracy: 0.7442 - 9s/epoch - 79ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.82421\n",
      "119/119 - 9s - loss: 0.4328 - accuracy: 0.8076 - val_loss: 0.4318 - val_accuracy: 0.8200 - 9s/epoch - 79ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82421\n",
      "119/119 - 9s - loss: 0.4159 - accuracy: 0.8136 - val_loss: 0.4264 - val_accuracy: 0.8137 - 9s/epoch - 78ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82421\n",
      "119/119 - 9s - loss: 0.3998 - accuracy: 0.8292 - val_loss: 0.4259 - val_accuracy: 0.8147 - 9s/epoch - 79ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.82421\n",
      "119/119 - 9s - loss: 0.4076 - accuracy: 0.8181 - val_loss: 0.3977 - val_accuracy: 0.8232 - 9s/epoch - 80ms/step\n",
      "Epoch 00020: early stopping\n",
      "TRAINING  78\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66526, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8862 - accuracy: 0.6489 - val_loss: 0.7696 - val_accuracy: 0.6653 - 13s/epoch - 106ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.66526\n",
      "119/119 - 9s - loss: 0.7424 - accuracy: 0.6668 - val_loss: 0.7325 - val_accuracy: 0.6653 - 9s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.66526\n",
      "119/119 - 10s - loss: 0.7181 - accuracy: 0.6668 - val_loss: 0.7143 - val_accuracy: 0.6653 - 10s/epoch - 81ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.66526\n",
      "119/119 - 9s - loss: 0.6846 - accuracy: 0.6668 - val_loss: 0.6530 - val_accuracy: 0.6653 - 9s/epoch - 79ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.66526 to 0.74421, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.6060 - accuracy: 0.7111 - val_loss: 0.5945 - val_accuracy: 0.7442 - 10s/epoch - 87ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.74421 to 0.74947, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5730 - accuracy: 0.7582 - val_loss: 0.5785 - val_accuracy: 0.7495 - 10s/epoch - 88ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.74947 to 0.76947, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5602 - accuracy: 0.7624 - val_loss: 0.5696 - val_accuracy: 0.7695 - 10s/epoch - 86ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76947\n",
      "119/119 - 9s - loss: 0.5525 - accuracy: 0.7682 - val_loss: 0.5743 - val_accuracy: 0.7495 - 9s/epoch - 79ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.76947 to 0.77053, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5449 - accuracy: 0.7709 - val_loss: 0.5517 - val_accuracy: 0.7705 - 10s/epoch - 88ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.77053 to 0.77158, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5355 - accuracy: 0.7772 - val_loss: 0.5454 - val_accuracy: 0.7716 - 10s/epoch - 87ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.77158 to 0.80000, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5253 - accuracy: 0.7743 - val_loss: 0.5328 - val_accuracy: 0.8000 - 10s/epoch - 87ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80000\n",
      "119/119 - 9s - loss: 0.5180 - accuracy: 0.7775 - val_loss: 0.5347 - val_accuracy: 0.7642 - 9s/epoch - 79ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.80000\n",
      "119/119 - 10s - loss: 0.5111 - accuracy: 0.7717 - val_loss: 0.5571 - val_accuracy: 0.7558 - 10s/epoch - 80ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.80000\n",
      "119/119 - 10s - loss: 0.5021 - accuracy: 0.7817 - val_loss: 0.4972 - val_accuracy: 0.7905 - 10s/epoch - 81ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.80000 to 0.80421, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4887 - accuracy: 0.7788 - val_loss: 0.4848 - val_accuracy: 0.8042 - 10s/epoch - 87ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.80421\n",
      "119/119 - 9s - loss: 0.4762 - accuracy: 0.7888 - val_loss: 0.4832 - val_accuracy: 0.7779 - 9s/epoch - 79ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.80421\n",
      "119/119 - 10s - loss: 0.4666 - accuracy: 0.7880 - val_loss: 0.4721 - val_accuracy: 0.7895 - 10s/epoch - 80ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.80421\n",
      "119/119 - 10s - loss: 0.4550 - accuracy: 0.7959 - val_loss: 0.4605 - val_accuracy: 0.7958 - 10s/epoch - 80ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.80421\n",
      "119/119 - 9s - loss: 0.4574 - accuracy: 0.7927 - val_loss: 0.4701 - val_accuracy: 0.7916 - 9s/epoch - 80ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.80421 to 0.80737, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4356 - accuracy: 0.8096 - val_loss: 0.4564 - val_accuracy: 0.8074 - 10s/epoch - 88ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.80737 to 0.80947, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4483 - accuracy: 0.7988 - val_loss: 0.4505 - val_accuracy: 0.8095 - 10s/epoch - 87ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.80947\n",
      "119/119 - 9s - loss: 0.4270 - accuracy: 0.8012 - val_loss: 0.4289 - val_accuracy: 0.8063 - 9s/epoch - 79ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.80947\n",
      "119/119 - 10s - loss: 0.4414 - accuracy: 0.7993 - val_loss: 0.4417 - val_accuracy: 0.8000 - 10s/epoch - 80ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.80947\n",
      "119/119 - 9s - loss: 0.4747 - accuracy: 0.7885 - val_loss: 0.5468 - val_accuracy: 0.7989 - 9s/epoch - 78ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.80947\n",
      "119/119 - 9s - loss: 0.4994 - accuracy: 0.7930 - val_loss: 0.4793 - val_accuracy: 0.7895 - 9s/epoch - 79ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.80947 to 0.81368, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4627 - accuracy: 0.8035 - val_loss: 0.4677 - val_accuracy: 0.8137 - 10s/epoch - 87ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.81368\n",
      "119/119 - 9s - loss: 0.4506 - accuracy: 0.8093 - val_loss: 0.4647 - val_accuracy: 0.8053 - 9s/epoch - 79ms/step\n",
      "Epoch 28/10000\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.81368\n",
      "119/119 - 10s - loss: 0.4609 - accuracy: 0.7998 - val_loss: 0.4749 - val_accuracy: 0.8074 - 10s/epoch - 80ms/step\n",
      "Epoch 29/10000\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.81368\n",
      "119/119 - 9s - loss: 0.4442 - accuracy: 0.8046 - val_loss: 0.4530 - val_accuracy: 0.7926 - 9s/epoch - 79ms/step\n",
      "Epoch 30/10000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.81368\n",
      "119/119 - 10s - loss: 0.4407 - accuracy: 0.8104 - val_loss: 0.4624 - val_accuracy: 0.7937 - 10s/epoch - 80ms/step\n",
      "Epoch 31/10000\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.81368 to 0.81579, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4333 - accuracy: 0.8077 - val_loss: 0.4391 - val_accuracy: 0.8158 - 10s/epoch - 88ms/step\n",
      "Epoch 32/10000\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.81579 to 0.82000, saving model to 78rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4249 - accuracy: 0.8143 - val_loss: 0.4397 - val_accuracy: 0.8200 - 10s/epoch - 86ms/step\n",
      "Epoch 33/10000\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.82000\n",
      "119/119 - 9s - loss: 0.4255 - accuracy: 0.8133 - val_loss: 0.4409 - val_accuracy: 0.8179 - 9s/epoch - 78ms/step\n",
      "Epoch 34/10000\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.82000\n",
      "119/119 - 9s - loss: 0.4228 - accuracy: 0.8093 - val_loss: 0.4322 - val_accuracy: 0.8137 - 9s/epoch - 80ms/step\n",
      "Epoch 35/10000\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.82000\n",
      "119/119 - 9s - loss: 0.4119 - accuracy: 0.8172 - val_loss: 0.4292 - val_accuracy: 0.8189 - 9s/epoch - 79ms/step\n",
      "Epoch 36/10000\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.82000\n",
      "119/119 - 9s - loss: 0.4167 - accuracy: 0.8114 - val_loss: 0.4264 - val_accuracy: 0.8032 - 9s/epoch - 78ms/step\n",
      "Epoch 37/10000\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.82000\n",
      "119/119 - 9s - loss: 0.4128 - accuracy: 0.8085 - val_loss: 0.4663 - val_accuracy: 0.7916 - 9s/epoch - 79ms/step\n",
      "Epoch 00037: early stopping\n",
      "TRAINING  79\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67861, saving model to 79rollingmean.10000nmodel.hdf5\n",
      "119/119 - 12s - loss: 0.8890 - accuracy: 0.6583 - val_loss: 0.7613 - val_accuracy: 0.6786 - 12s/epoch - 105ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67861\n",
      "119/119 - 9s - loss: 0.7498 - accuracy: 0.6654 - val_loss: 0.7243 - val_accuracy: 0.6786 - 9s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67861\n",
      "119/119 - 10s - loss: 0.7305 - accuracy: 0.6654 - val_loss: 0.7157 - val_accuracy: 0.6786 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67861\n",
      "119/119 - 10s - loss: 0.7252 - accuracy: 0.6654 - val_loss: 0.7122 - val_accuracy: 0.6786 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67861\n",
      "119/119 - 9s - loss: 0.7225 - accuracy: 0.6654 - val_loss: 0.7108 - val_accuracy: 0.6786 - 9s/epoch - 79ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67861\n",
      "119/119 - 9s - loss: 0.7196 - accuracy: 0.6654 - val_loss: 0.7063 - val_accuracy: 0.6786 - 9s/epoch - 80ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  80\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67123, saving model to 80rollingmean.10000nmodel.hdf5\n",
      "119/119 - 12s - loss: 0.8736 - accuracy: 0.6682 - val_loss: 0.7395 - val_accuracy: 0.6712 - 12s/epoch - 105ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67123\n",
      "119/119 - 9s - loss: 0.7199 - accuracy: 0.6692 - val_loss: 0.6778 - val_accuracy: 0.6712 - 9s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67123\n",
      "119/119 - 9s - loss: 0.6576 - accuracy: 0.6692 - val_loss: 0.5907 - val_accuracy: 0.6712 - 9s/epoch - 79ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67123 to 0.76185, saving model to 80rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5941 - accuracy: 0.7293 - val_loss: 0.5509 - val_accuracy: 0.7619 - 10s/epoch - 87ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.76185 to 0.77555, saving model to 80rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5759 - accuracy: 0.7675 - val_loss: 0.5375 - val_accuracy: 0.7756 - 10s/epoch - 85ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.77555 to 0.78714, saving model to 80rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5643 - accuracy: 0.7731 - val_loss: 0.5287 - val_accuracy: 0.7871 - 10s/epoch - 87ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.78714 to 0.78820, saving model to 80rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5562 - accuracy: 0.7699 - val_loss: 0.5195 - val_accuracy: 0.7882 - 10s/epoch - 87ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.78820 to 0.80400, saving model to 80rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5440 - accuracy: 0.7762 - val_loss: 0.5106 - val_accuracy: 0.8040 - 10s/epoch - 85ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80400\n",
      "119/119 - 9s - loss: 0.5372 - accuracy: 0.7770 - val_loss: 0.5010 - val_accuracy: 0.8030 - 9s/epoch - 78ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80400\n",
      "119/119 - 9s - loss: 0.5234 - accuracy: 0.7820 - val_loss: 0.4864 - val_accuracy: 0.7956 - 9s/epoch - 78ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.80400\n",
      "119/119 - 10s - loss: 0.5162 - accuracy: 0.7847 - val_loss: 0.4784 - val_accuracy: 0.7914 - 10s/epoch - 80ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80400\n",
      "119/119 - 9s - loss: 0.4984 - accuracy: 0.7902 - val_loss: 0.4713 - val_accuracy: 0.7850 - 9s/epoch - 78ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.80400 to 0.82192, saving model to 80rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4875 - accuracy: 0.7899 - val_loss: 0.4450 - val_accuracy: 0.8219 - 10s/epoch - 85ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82192\n",
      "119/119 - 9s - loss: 0.4796 - accuracy: 0.7928 - val_loss: 0.4424 - val_accuracy: 0.7893 - 9s/epoch - 79ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82192\n",
      "119/119 - 10s - loss: 0.4634 - accuracy: 0.7994 - val_loss: 0.4855 - val_accuracy: 0.7819 - 10s/epoch - 80ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82192\n",
      "119/119 - 9s - loss: 0.4509 - accuracy: 0.7986 - val_loss: 0.4087 - val_accuracy: 0.8219 - 9s/epoch - 79ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.82192 to 0.84510, saving model to 80rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4473 - accuracy: 0.8028 - val_loss: 0.4120 - val_accuracy: 0.8451 - 10s/epoch - 88ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84510\n",
      "119/119 - 9s - loss: 0.4358 - accuracy: 0.8123 - val_loss: 0.4032 - val_accuracy: 0.8377 - 9s/epoch - 78ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84510 to 0.85564, saving model to 80rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4339 - accuracy: 0.8071 - val_loss: 0.3972 - val_accuracy: 0.8556 - 10s/epoch - 87ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85564\n",
      "119/119 - 9s - loss: 0.4315 - accuracy: 0.8121 - val_loss: 0.3963 - val_accuracy: 0.8219 - 9s/epoch - 78ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85564\n",
      "119/119 - 9s - loss: 0.4293 - accuracy: 0.8071 - val_loss: 0.3851 - val_accuracy: 0.8409 - 9s/epoch - 80ms/step\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.64910 to 0.76080, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.6202 - accuracy: 0.6896 - val_loss: 0.6149 - val_accuracy: 0.7608 - 11s/epoch - 91ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.76080 to 0.76607, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.5804 - accuracy: 0.7642 - val_loss: 0.5916 - val_accuracy: 0.7661 - 11s/epoch - 92ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.76607 to 0.78609, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.5670 - accuracy: 0.7716 - val_loss: 0.5791 - val_accuracy: 0.7861 - 11s/epoch - 92ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.78609\n",
      "119/119 - 9s - loss: 0.5575 - accuracy: 0.7743 - val_loss: 0.5684 - val_accuracy: 0.7861 - 9s/epoch - 77ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.78609 to 0.78714, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.5454 - accuracy: 0.7785 - val_loss: 0.5566 - val_accuracy: 0.7871 - 11s/epoch - 94ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.78714\n",
      "119/119 - 9s - loss: 0.5318 - accuracy: 0.7787 - val_loss: 0.5413 - val_accuracy: 0.7871 - 9s/epoch - 79ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.78714 to 0.79241, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.5204 - accuracy: 0.7743 - val_loss: 0.5262 - val_accuracy: 0.7924 - 11s/epoch - 92ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79241\n",
      "119/119 - 9s - loss: 0.5072 - accuracy: 0.7764 - val_loss: 0.5136 - val_accuracy: 0.7903 - 9s/epoch - 78ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.79241\n",
      "119/119 - 10s - loss: 0.5022 - accuracy: 0.7729 - val_loss: 0.5026 - val_accuracy: 0.7871 - 10s/epoch - 80ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.79241 to 0.79979, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4856 - accuracy: 0.7867 - val_loss: 0.4898 - val_accuracy: 0.7998 - 11s/epoch - 93ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.79979\n",
      "119/119 - 9s - loss: 0.4828 - accuracy: 0.7848 - val_loss: 0.4876 - val_accuracy: 0.7903 - 9s/epoch - 79ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.79979\n",
      "119/119 - 10s - loss: 0.4662 - accuracy: 0.7948 - val_loss: 0.5057 - val_accuracy: 0.7734 - 10s/epoch - 80ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.79979\n",
      "119/119 - 9s - loss: 0.4548 - accuracy: 0.8033 - val_loss: 0.4661 - val_accuracy: 0.7987 - 9s/epoch - 79ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.79979 to 0.80822, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4514 - accuracy: 0.8027 - val_loss: 0.4503 - val_accuracy: 0.8082 - 11s/epoch - 92ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.80822 to 0.81243, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4448 - accuracy: 0.8133 - val_loss: 0.4689 - val_accuracy: 0.8124 - 11s/epoch - 93ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.81243 to 0.81876, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4434 - accuracy: 0.8080 - val_loss: 0.4431 - val_accuracy: 0.8188 - 11s/epoch - 90ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.81876 to 0.82508, saving model to 81rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4291 - accuracy: 0.8157 - val_loss: 0.4482 - val_accuracy: 0.8251 - 11s/epoch - 91ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.82508\n",
      "119/119 - 9s - loss: 0.4313 - accuracy: 0.8107 - val_loss: 0.4432 - val_accuracy: 0.8008 - 9s/epoch - 78ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.82508\n",
      "119/119 - 10s - loss: 0.4108 - accuracy: 0.8165 - val_loss: 0.4686 - val_accuracy: 0.7903 - 10s/epoch - 81ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.82508\n",
      "119/119 - 10s - loss: 0.4064 - accuracy: 0.8217 - val_loss: 0.4252 - val_accuracy: 0.8166 - 10s/epoch - 81ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.82508\n",
      "119/119 - 10s - loss: 0.3991 - accuracy: 0.8257 - val_loss: 0.4286 - val_accuracy: 0.7987 - 10s/epoch - 80ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.82508\n",
      "119/119 - 10s - loss: 0.4703 - accuracy: 0.7893 - val_loss: 0.4772 - val_accuracy: 0.8124 - 10s/epoch - 80ms/step\n",
      "Epoch 00026: early stopping\n",
      "TRAINING  82\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68987, saving model to 82rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8933 - accuracy: 0.6529 - val_loss: 0.7514 - val_accuracy: 0.6899 - 13s/epoch - 110ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68987\n",
      "119/119 - 10s - loss: 0.7385 - accuracy: 0.6690 - val_loss: 0.7132 - val_accuracy: 0.6899 - 10s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68987\n",
      "119/119 - 9s - loss: 0.7172 - accuracy: 0.6690 - val_loss: 0.7068 - val_accuracy: 0.6899 - 9s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68987\n",
      "119/119 - 10s - loss: 0.7113 - accuracy: 0.6690 - val_loss: 0.7044 - val_accuracy: 0.6899 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68987\n",
      "119/119 - 10s - loss: 0.7071 - accuracy: 0.6690 - val_loss: 0.6998 - val_accuracy: 0.6899 - 10s/epoch - 80ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68987\n",
      "119/119 - 10s - loss: 0.6998 - accuracy: 0.6690 - val_loss: 0.6864 - val_accuracy: 0.6899 - 10s/epoch - 81ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  83\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65401, saving model to 83rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8802 - accuracy: 0.6722 - val_loss: 0.7702 - val_accuracy: 0.6540 - 13s/epoch - 106ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.65401\n",
      "119/119 - 10s - loss: 0.7252 - accuracy: 0.6793 - val_loss: 0.7388 - val_accuracy: 0.6540 - 10s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.65401\n",
      "119/119 - 9s - loss: 0.7085 - accuracy: 0.6793 - val_loss: 0.7325 - val_accuracy: 0.6540 - 9s/epoch - 79ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.65401\n",
      "119/119 - 9s - loss: 0.7042 - accuracy: 0.6793 - val_loss: 0.7289 - val_accuracy: 0.6540 - 9s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.65401\n",
      "119/119 - 9s - loss: 0.7014 - accuracy: 0.6793 - val_loss: 0.7254 - val_accuracy: 0.6540 - 9s/epoch - 80ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65401\n",
      "119/119 - 9s - loss: 0.6968 - accuracy: 0.6793 - val_loss: 0.7197 - val_accuracy: 0.6540 - 9s/epoch - 79ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  84\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67687, saving model to 84rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8752 - accuracy: 0.6758 - val_loss: 0.7557 - val_accuracy: 0.6769 - 13s/epoch - 109ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67687\n",
      "119/119 - 9s - loss: 0.7245 - accuracy: 0.6758 - val_loss: 0.7168 - val_accuracy: 0.6769 - 9s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67687\n",
      "119/119 - 9s - loss: 0.6985 - accuracy: 0.6758 - val_loss: 0.6992 - val_accuracy: 0.6769 - 9s/epoch - 79ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67687\n",
      "119/119 - 9s - loss: 0.6670 - accuracy: 0.6758 - val_loss: 0.6470 - val_accuracy: 0.6769 - 9s/epoch - 78ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67687 to 0.70011, saving model to 84rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.6086 - accuracy: 0.6803 - val_loss: 0.6093 - val_accuracy: 0.7001 - 11s/epoch - 89ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.70011\n",
      "119/119 - 9s - loss: 0.5814 - accuracy: 0.7215 - val_loss: 0.5966 - val_accuracy: 0.6769 - 9s/epoch - 78ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.70011 to 0.77086, saving model to 84rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5557 - accuracy: 0.7606 - val_loss: 0.5622 - val_accuracy: 0.7709 - 10s/epoch - 87ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.77086 to 0.78986, saving model to 84rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5241 - accuracy: 0.7812 - val_loss: 0.5318 - val_accuracy: 0.7899 - 10s/epoch - 87ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.78986\n",
      "119/119 - 9s - loss: 0.5054 - accuracy: 0.7785 - val_loss: 0.5211 - val_accuracy: 0.7761 - 9s/epoch - 78ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.78986 to 0.79197, saving model to 84rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4923 - accuracy: 0.7843 - val_loss: 0.5399 - val_accuracy: 0.7920 - 10s/epoch - 87ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79197\n",
      "119/119 - 9s - loss: 0.4866 - accuracy: 0.7825 - val_loss: 0.5041 - val_accuracy: 0.7878 - 9s/epoch - 78ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79197\n",
      "119/119 - 9s - loss: 0.4795 - accuracy: 0.7838 - val_loss: 0.5244 - val_accuracy: 0.7899 - 9s/epoch - 80ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.79197 to 0.79831, saving model to 84rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4707 - accuracy: 0.7949 - val_loss: 0.4982 - val_accuracy: 0.7983 - 10s/epoch - 88ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.79831 to 0.80253, saving model to 84rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4630 - accuracy: 0.7909 - val_loss: 0.4704 - val_accuracy: 0.8025 - 11s/epoch - 89ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.80253 to 0.80570, saving model to 84rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4451 - accuracy: 0.7986 - val_loss: 0.4682 - val_accuracy: 0.8057 - 10s/epoch - 87ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.80570 to 0.81732, saving model to 84rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4404 - accuracy: 0.8076 - val_loss: 0.4646 - val_accuracy: 0.8173 - 10s/epoch - 87ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.81732\n",
      "119/119 - 9s - loss: 0.4406 - accuracy: 0.8062 - val_loss: 0.4798 - val_accuracy: 0.8015 - 9s/epoch - 77ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.81732\n",
      "119/119 - 9s - loss: 0.4371 - accuracy: 0.8073 - val_loss: 0.4529 - val_accuracy: 0.8078 - 9s/epoch - 77ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.81732\n",
      "119/119 - 9s - loss: 0.4432 - accuracy: 0.8020 - val_loss: 0.4665 - val_accuracy: 0.7994 - 9s/epoch - 79ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.81732\n",
      "119/119 - 9s - loss: 0.4275 - accuracy: 0.8139 - val_loss: 0.4493 - val_accuracy: 0.8099 - 9s/epoch - 79ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.81732\n",
      "119/119 - 9s - loss: 0.4500 - accuracy: 0.7946 - val_loss: 0.4909 - val_accuracy: 0.7835 - 9s/epoch - 79ms/step\n",
      "Epoch 00021: early stopping\n",
      "TRAINING  85\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67265, saving model to 85rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8722 - accuracy: 0.6788 - val_loss: 0.7591 - val_accuracy: 0.6727 - 13s/epoch - 112ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67265\n",
      "119/119 - 9s - loss: 0.7269 - accuracy: 0.6788 - val_loss: 0.7248 - val_accuracy: 0.6727 - 9s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67265\n",
      "119/119 - 9s - loss: 0.7077 - accuracy: 0.6788 - val_loss: 0.7178 - val_accuracy: 0.6727 - 9s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67265\n",
      "119/119 - 9s - loss: 0.7030 - accuracy: 0.6788 - val_loss: 0.7161 - val_accuracy: 0.6727 - 9s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67265\n",
      "119/119 - 9s - loss: 0.7016 - accuracy: 0.6788 - val_loss: 0.7156 - val_accuracy: 0.6727 - 9s/epoch - 79ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67265\n",
      "119/119 - 9s - loss: 0.7011 - accuracy: 0.6788 - val_loss: 0.7148 - val_accuracy: 0.6727 - 9s/epoch - 79ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  86\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69483, saving model to 86rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8695 - accuracy: 0.6580 - val_loss: 0.7306 - val_accuracy: 0.6948 - 13s/epoch - 105ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.69483\n",
      "119/119 - 9s - loss: 0.7129 - accuracy: 0.6755 - val_loss: 0.6813 - val_accuracy: 0.6948 - 9s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.69483\n",
      "119/119 - 9s - loss: 0.6508 - accuracy: 0.6755 - val_loss: 0.5863 - val_accuracy: 0.6948 - 9s/epoch - 79ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.69483 to 0.81521, saving model to 86rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5724 - accuracy: 0.7323 - val_loss: 0.5323 - val_accuracy: 0.8152 - 10s/epoch - 86ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.81521\n",
      "119/119 - 9s - loss: 0.5420 - accuracy: 0.7785 - val_loss: 0.5077 - val_accuracy: 0.8120 - 9s/epoch - 79ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.81521 to 0.82365, saving model to 86rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5221 - accuracy: 0.7822 - val_loss: 0.4885 - val_accuracy: 0.8237 - 10s/epoch - 87ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.82365\n",
      "119/119 - 9s - loss: 0.5046 - accuracy: 0.7809 - val_loss: 0.4768 - val_accuracy: 0.8120 - 9s/epoch - 78ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.82365\n",
      "119/119 - 9s - loss: 0.4946 - accuracy: 0.7910 - val_loss: 0.4646 - val_accuracy: 0.8099 - 9s/epoch - 79ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.82365\n",
      "119/119 - 9s - loss: 0.4775 - accuracy: 0.7981 - val_loss: 0.5143 - val_accuracy: 0.7814 - 9s/epoch - 80ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82365\n",
      "119/119 - 9s - loss: 0.4671 - accuracy: 0.7994 - val_loss: 0.4587 - val_accuracy: 0.7983 - 9s/epoch - 79ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82365\n",
      "119/119 - 9s - loss: 0.4542 - accuracy: 0.7997 - val_loss: 0.4643 - val_accuracy: 0.7899 - 9s/epoch - 79ms/step\n",
      "Epoch 00011: early stopping\n",
      "TRAINING  87\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68182, saving model to 87rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8570 - accuracy: 0.6809 - val_loss: 0.7188 - val_accuracy: 0.6818 - 13s/epoch - 110ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68182\n",
      "119/119 - 9s - loss: 0.7141 - accuracy: 0.6812 - val_loss: 0.6871 - val_accuracy: 0.6818 - 9s/epoch - 80ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68182\n",
      "119/119 - 9s - loss: 0.7006 - accuracy: 0.6812 - val_loss: 0.6769 - val_accuracy: 0.6818 - 9s/epoch - 79ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.68182\n",
      "119/119 - 9s - loss: 0.6917 - accuracy: 0.6812 - val_loss: 0.6633 - val_accuracy: 0.6818 - 9s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68182\n",
      "119/119 - 9s - loss: 0.6631 - accuracy: 0.6812 - val_loss: 0.6095 - val_accuracy: 0.6818 - 9s/epoch - 79ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.68182 to 0.79704, saving model to 87rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5850 - accuracy: 0.7280 - val_loss: 0.5281 - val_accuracy: 0.7970 - 10s/epoch - 87ms/step\n",
      "Epoch 7/10000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.79704\n",
      "119/119 - 9s - loss: 0.5480 - accuracy: 0.7756 - val_loss: 0.5101 - val_accuracy: 0.7844 - 9s/epoch - 79ms/step\n",
      "Epoch 8/10000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.79704\n",
      "119/119 - 10s - loss: 0.5309 - accuracy: 0.7838 - val_loss: 0.5134 - val_accuracy: 0.7696 - 10s/epoch - 81ms/step\n",
      "Epoch 9/10000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.79704 to 0.80550, saving model to 87rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.5204 - accuracy: 0.7774 - val_loss: 0.4752 - val_accuracy: 0.8055 - 11s/epoch - 89ms/step\n",
      "Epoch 10/10000\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.80550 to 0.81607, saving model to 87rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.5073 - accuracy: 0.7861 - val_loss: 0.4659 - val_accuracy: 0.8161 - 10s/epoch - 88ms/step\n",
      "Epoch 11/10000\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81607\n",
      "119/119 - 9s - loss: 0.4926 - accuracy: 0.7973 - val_loss: 0.4559 - val_accuracy: 0.8118 - 9s/epoch - 80ms/step\n",
      "Epoch 12/10000\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.81607 to 0.81712, saving model to 87rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4905 - accuracy: 0.7861 - val_loss: 0.4489 - val_accuracy: 0.8171 - 10s/epoch - 87ms/step\n",
      "Epoch 13/10000\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.81712\n",
      "119/119 - 9s - loss: 0.4773 - accuracy: 0.7973 - val_loss: 0.4775 - val_accuracy: 0.7812 - 9s/epoch - 78ms/step\n",
      "Epoch 14/10000\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.81712 to 0.82875, saving model to 87rollingmean.10000nmodel.hdf5\n",
      "119/119 - 10s - loss: 0.4686 - accuracy: 0.8004 - val_loss: 0.4334 - val_accuracy: 0.8288 - 10s/epoch - 88ms/step\n",
      "Epoch 15/10000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82875\n",
      "119/119 - 9s - loss: 0.4585 - accuracy: 0.8073 - val_loss: 0.4188 - val_accuracy: 0.8129 - 9s/epoch - 79ms/step\n",
      "Epoch 16/10000\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82875\n",
      "119/119 - 9s - loss: 0.4447 - accuracy: 0.8163 - val_loss: 0.3974 - val_accuracy: 0.8214 - 9s/epoch - 78ms/step\n",
      "Epoch 17/10000\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.82875\n",
      "119/119 - 10s - loss: 0.4437 - accuracy: 0.8084 - val_loss: 0.4404 - val_accuracy: 0.7970 - 10s/epoch - 81ms/step\n",
      "Epoch 18/10000\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.82875 to 0.82981, saving model to 87rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4362 - accuracy: 0.8158 - val_loss: 0.4031 - val_accuracy: 0.8298 - 11s/epoch - 90ms/step\n",
      "Epoch 19/10000\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.82981 to 0.85941, saving model to 87rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.4229 - accuracy: 0.8221 - val_loss: 0.3687 - val_accuracy: 0.8594 - 11s/epoch - 89ms/step\n",
      "Epoch 20/10000\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85941\n",
      "119/119 - 9s - loss: 0.4192 - accuracy: 0.8189 - val_loss: 0.4069 - val_accuracy: 0.8214 - 9s/epoch - 77ms/step\n",
      "Epoch 21/10000\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85941\n",
      "119/119 - 9s - loss: 0.3998 - accuracy: 0.8308 - val_loss: 0.3896 - val_accuracy: 0.8203 - 9s/epoch - 80ms/step\n",
      "Epoch 22/10000\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85941\n",
      "119/119 - 9s - loss: 0.4036 - accuracy: 0.8253 - val_loss: 0.3448 - val_accuracy: 0.8552 - 9s/epoch - 80ms/step\n",
      "Epoch 23/10000\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85941 to 0.88478, saving model to 87rollingmean.10000nmodel.hdf5\n",
      "119/119 - 11s - loss: 0.3797 - accuracy: 0.8340 - val_loss: 0.3346 - val_accuracy: 0.8848 - 11s/epoch - 89ms/step\n",
      "Epoch 24/10000\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.88478\n",
      "119/119 - 9s - loss: 0.3865 - accuracy: 0.8419 - val_loss: 0.3815 - val_accuracy: 0.8541 - 9s/epoch - 79ms/step\n",
      "Epoch 25/10000\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.88478\n",
      "119/119 - 9s - loss: 0.3804 - accuracy: 0.8409 - val_loss: 0.3485 - val_accuracy: 0.8340 - 9s/epoch - 79ms/step\n",
      "Epoch 26/10000\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.88478\n",
      "119/119 - 10s - loss: 0.3768 - accuracy: 0.8395 - val_loss: 0.3149 - val_accuracy: 0.8721 - 10s/epoch - 81ms/step\n",
      "Epoch 27/10000\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.88478\n",
      "119/119 - 9s - loss: 0.3713 - accuracy: 0.8456 - val_loss: 0.3356 - val_accuracy: 0.8531 - 9s/epoch - 79ms/step\n",
      "Epoch 28/10000\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.88478\n",
      "119/119 - 9s - loss: 0.3653 - accuracy: 0.8485 - val_loss: 0.3406 - val_accuracy: 0.8457 - 9s/epoch - 79ms/step\n",
      "Epoch 00028: early stopping\n",
      "TRAINING  88\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69979, saving model to 88rollingmean.10000nmodel.hdf5\n",
      "119/119 - 13s - loss: 0.8877 - accuracy: 0.6768 - val_loss: 0.7339 - val_accuracy: 0.6998 - 13s/epoch - 106ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.69979\n",
      "119/119 - 9s - loss: 0.7259 - accuracy: 0.6787 - val_loss: 0.6874 - val_accuracy: 0.6998 - 9s/epoch - 79ms/step\n",
      "Epoch 3/10000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.69979\n",
      "119/119 - 10s - loss: 0.7046 - accuracy: 0.6787 - val_loss: 0.6786 - val_accuracy: 0.6998 - 10s/epoch - 80ms/step\n",
      "Epoch 4/10000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.69979\n",
      "119/119 - 10s - loss: 0.6998 - accuracy: 0.6787 - val_loss: 0.6761 - val_accuracy: 0.6998 - 10s/epoch - 80ms/step\n",
      "Epoch 5/10000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.69979\n",
      "119/119 - 10s - loss: 0.6986 - accuracy: 0.6787 - val_loss: 0.6744 - val_accuracy: 0.6998 - 10s/epoch - 80ms/step\n",
      "Epoch 6/10000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.69979\n",
      "119/119 - 9s - loss: 0.6983 - accuracy: 0.6787 - val_loss: 0.6734 - val_accuracy: 0.6998 - 9s/epoch - 80ms/step\n",
      "Epoch 00006: early stopping\n",
      "TRAINING  89\n",
      "Epoch 1/10000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69947, saving model to 89rollingmean.10000nmodel.hdf5\n",
      "119/119 - 14s - loss: 0.8538 - accuracy: 0.6799 - val_loss: 0.7145 - val_accuracy: 0.6995 - 14s/epoch - 115ms/step\n",
      "Epoch 2/10000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.69947\n",
      "119/119 - 10s - loss: 0.6908 - accuracy: 0.6799 - val_loss: 0.6540 - val_accuracy: 0.6995 - 10s/epoch - 80ms/step\n",
      "Epoch 3/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, patience \u001b[38;5;241m=\u001b[39m stop_epoch_num, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m cp \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrollingmean.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10000nmodel.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     16\u001b[0m                              monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m                              verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     18\u001b[0m                              save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m                              mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mDeepLOB_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m windowsizes\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     24\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1216\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1211\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1212\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1213\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1214\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1215\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1216\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1218\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    907\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 910\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    912\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    913\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    940\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    941\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3128\u001b[0m   (graph_function,\n\u001b[1;32m   3129\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1955\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1958\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1959\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1961\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m     args,\n\u001b[1;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1964\u001b[0m     executing_eagerly)\n\u001b[1;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    607\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    611\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "windowsizes = []\n",
    "accuracy = []\n",
    "for i in range(50, 100+1):\n",
    "    print(\"TRAINING \", i)\n",
    "    x, y  = get_x_y(d, i)\n",
    "    xt = reshapex(x)\n",
    "    yt = reshapey(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(xt,yt,test_size = 0.2)\n",
    "    X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "    \n",
    "    DeepLOB_model = initiate_DeepLOB_model(lookback_timestep, feature_num, conv_filter_num, inception_num, LSTM_num, leaky_relu_alpha,\n",
    "                              loss, optimizer, metrics)\n",
    "\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', patience = stop_epoch_num, verbose=1)\n",
    "    cp = ModelCheckpoint(filepath=str(i) + 'rollingmean.' +'10000nmodel.hdf5', \n",
    "                                 monitor='val_accuracy',\n",
    "                                 verbose=1, \n",
    "                                 save_best_only=True,\n",
    "                                 mode='max')\n",
    "\n",
    "    history = DeepLOB_model.fit(X_train, y_train, epochs=num_epoch, batch_size=batch_size, verbose=2, validation_data=(X_test, y_test), \n",
    "                                callbacks = [es, cp])\n",
    "    windowsizes.append(i)\n",
    "    accuracy.append(history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a0254-970c-4448-a29c-9394cb84c2e6",
   "metadata": {},
   "source": [
    "## Window size 10 -> 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6cec207-701e-4ba1-8b25-814e477bc830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa8547ba790>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(windowsizes, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa65bd-a463-4d16-a56e-1761e33475a5",
   "metadata": {},
   "source": [
    "## Window size 30 -> 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bc1fa0c-bf12-4243-9721-9aaa6e23a24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa8060e58b0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(windowsizes, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bddb5-739d-4c79-8502-83e0b525d22d",
   "metadata": {},
   "source": [
    "## Window size 50 -> 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faeb6cba-19ec-4329-86d9-c534b4f5ec2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe8820556d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(windowsizes, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c07f41-e18b-4d3f-940d-f32b29656386",
   "metadata": {},
   "source": [
    "**Conclusion:** I had to cut the calculations in 3 parts, but in the end got my best accuracies using window sizes ranging from 10 to 90.\n",
    "It does seem that the model flucutuates a lot on any given range, although one thing is clearly visible in the graphs: bigger window size on average means better model accuracy. Next parameter tuning should be about the neural network parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
