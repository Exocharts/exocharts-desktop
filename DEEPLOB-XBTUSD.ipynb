{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0495c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89634d",
   "metadata": {},
   "source": [
    "Paper: https://arxiv.org/pdf/1808.03668.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe057368",
   "metadata": {},
   "source": [
    "### Data of XBTUSD 10 level orderbook of 2020-09-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd316037",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"bitmex_book_snapshot_25_2020-09-01_XBTUSD.csv\")\n",
    "d = d.sort_values(by = 'timestamp')\n",
    "cols =    ['asks['+str(i)+'].price' for i in range(10)] \\\n",
    "        + ['asks['+str(i)+'].amount' for i in range(10)] \\\n",
    "        + ['bids['+str(i)+'].price' for i in range(10)] \\\n",
    "        + ['bids['+str(i)+'].amount' for i in range(10)] \n",
    "d = d[cols]\n",
    "d = d.apply(zscore)\n",
    "d = d.head(500000) # not enough power to run the full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc67c0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de472196-c23b-4baa-9317-4fad87f5804c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asks[0].price</th>\n",
       "      <th>asks[1].price</th>\n",
       "      <th>asks[2].price</th>\n",
       "      <th>asks[3].price</th>\n",
       "      <th>asks[4].price</th>\n",
       "      <th>asks[5].price</th>\n",
       "      <th>asks[6].price</th>\n",
       "      <th>asks[7].price</th>\n",
       "      <th>asks[8].price</th>\n",
       "      <th>asks[9].price</th>\n",
       "      <th>...</th>\n",
       "      <th>bids[0].amount</th>\n",
       "      <th>bids[1].amount</th>\n",
       "      <th>bids[2].amount</th>\n",
       "      <th>bids[3].amount</th>\n",
       "      <th>bids[4].amount</th>\n",
       "      <th>bids[5].amount</th>\n",
       "      <th>bids[6].amount</th>\n",
       "      <th>bids[7].amount</th>\n",
       "      <th>bids[8].amount</th>\n",
       "      <th>bids[9].amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.715884</td>\n",
       "      <td>-1.716104</td>\n",
       "      <td>-1.716244</td>\n",
       "      <td>-1.716319</td>\n",
       "      <td>-1.716381</td>\n",
       "      <td>-1.716440</td>\n",
       "      <td>-1.716476</td>\n",
       "      <td>-1.716506</td>\n",
       "      <td>-1.716525</td>\n",
       "      <td>-1.716545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534043</td>\n",
       "      <td>-0.333162</td>\n",
       "      <td>-0.154572</td>\n",
       "      <td>-0.344645</td>\n",
       "      <td>-0.372711</td>\n",
       "      <td>-0.334547</td>\n",
       "      <td>-0.406668</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>-0.446469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.715884</td>\n",
       "      <td>-1.716104</td>\n",
       "      <td>-1.716244</td>\n",
       "      <td>-1.716319</td>\n",
       "      <td>-1.716381</td>\n",
       "      <td>-1.716440</td>\n",
       "      <td>-1.716476</td>\n",
       "      <td>-1.716506</td>\n",
       "      <td>-1.716525</td>\n",
       "      <td>-1.716545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534043</td>\n",
       "      <td>-0.333162</td>\n",
       "      <td>-0.154572</td>\n",
       "      <td>-0.344645</td>\n",
       "      <td>-0.372711</td>\n",
       "      <td>-0.334547</td>\n",
       "      <td>-0.406668</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>-0.446469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.715884</td>\n",
       "      <td>-1.716104</td>\n",
       "      <td>-1.716244</td>\n",
       "      <td>-1.716319</td>\n",
       "      <td>-1.716381</td>\n",
       "      <td>-1.716440</td>\n",
       "      <td>-1.716476</td>\n",
       "      <td>-1.716506</td>\n",
       "      <td>-1.716525</td>\n",
       "      <td>-1.716545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534043</td>\n",
       "      <td>-0.333162</td>\n",
       "      <td>-0.154572</td>\n",
       "      <td>-0.344645</td>\n",
       "      <td>-0.372711</td>\n",
       "      <td>-0.334547</td>\n",
       "      <td>-0.406668</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>1.046836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.715884</td>\n",
       "      <td>-1.716104</td>\n",
       "      <td>-1.716244</td>\n",
       "      <td>-1.716319</td>\n",
       "      <td>-1.716381</td>\n",
       "      <td>-1.716440</td>\n",
       "      <td>-1.716476</td>\n",
       "      <td>-1.716506</td>\n",
       "      <td>-1.716525</td>\n",
       "      <td>-1.716545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534043</td>\n",
       "      <td>-0.333162</td>\n",
       "      <td>-0.154572</td>\n",
       "      <td>-0.344645</td>\n",
       "      <td>-0.372711</td>\n",
       "      <td>-0.334547</td>\n",
       "      <td>-0.406668</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>1.047677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.715884</td>\n",
       "      <td>-1.716104</td>\n",
       "      <td>-1.716244</td>\n",
       "      <td>-1.716319</td>\n",
       "      <td>-1.716381</td>\n",
       "      <td>-1.716440</td>\n",
       "      <td>-1.716476</td>\n",
       "      <td>-1.716506</td>\n",
       "      <td>-1.716525</td>\n",
       "      <td>-1.716545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534043</td>\n",
       "      <td>-0.333162</td>\n",
       "      <td>-0.154572</td>\n",
       "      <td>-0.344645</td>\n",
       "      <td>-0.372711</td>\n",
       "      <td>-0.334547</td>\n",
       "      <td>-0.406668</td>\n",
       "      <td>-0.004461</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>1.047677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>-1.926267</td>\n",
       "      <td>-1.926490</td>\n",
       "      <td>-1.926630</td>\n",
       "      <td>-1.926703</td>\n",
       "      <td>-1.926764</td>\n",
       "      <td>-1.926822</td>\n",
       "      <td>-1.926857</td>\n",
       "      <td>-1.926886</td>\n",
       "      <td>-1.926903</td>\n",
       "      <td>-1.926923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433030</td>\n",
       "      <td>-0.383804</td>\n",
       "      <td>-0.346235</td>\n",
       "      <td>0.282216</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.610318</td>\n",
       "      <td>1.691306</td>\n",
       "      <td>3.899836</td>\n",
       "      <td>0.080415</td>\n",
       "      <td>1.173897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>-1.926267</td>\n",
       "      <td>-1.926490</td>\n",
       "      <td>-1.926630</td>\n",
       "      <td>-1.926703</td>\n",
       "      <td>-1.926764</td>\n",
       "      <td>-1.926822</td>\n",
       "      <td>-1.926857</td>\n",
       "      <td>-1.926886</td>\n",
       "      <td>-1.926903</td>\n",
       "      <td>-1.926923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397425</td>\n",
       "      <td>-0.383804</td>\n",
       "      <td>-0.346235</td>\n",
       "      <td>0.282216</td>\n",
       "      <td>0.353270</td>\n",
       "      <td>0.610318</td>\n",
       "      <td>1.691306</td>\n",
       "      <td>3.899836</td>\n",
       "      <td>0.080415</td>\n",
       "      <td>1.173897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>-1.926267</td>\n",
       "      <td>-1.926490</td>\n",
       "      <td>-1.926630</td>\n",
       "      <td>-1.926703</td>\n",
       "      <td>-1.926764</td>\n",
       "      <td>-1.926822</td>\n",
       "      <td>-1.926857</td>\n",
       "      <td>-1.926886</td>\n",
       "      <td>-1.926903</td>\n",
       "      <td>-1.926923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397425</td>\n",
       "      <td>-0.383804</td>\n",
       "      <td>-0.346235</td>\n",
       "      <td>0.282216</td>\n",
       "      <td>0.392052</td>\n",
       "      <td>0.610318</td>\n",
       "      <td>1.691306</td>\n",
       "      <td>3.899836</td>\n",
       "      <td>0.080415</td>\n",
       "      <td>1.173897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>-1.926267</td>\n",
       "      <td>-1.926490</td>\n",
       "      <td>-1.926630</td>\n",
       "      <td>-1.926703</td>\n",
       "      <td>-1.926764</td>\n",
       "      <td>-1.926822</td>\n",
       "      <td>-1.926857</td>\n",
       "      <td>-1.926886</td>\n",
       "      <td>-1.926903</td>\n",
       "      <td>-1.926923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397425</td>\n",
       "      <td>-0.383804</td>\n",
       "      <td>-0.346235</td>\n",
       "      <td>0.282216</td>\n",
       "      <td>0.392052</td>\n",
       "      <td>0.596976</td>\n",
       "      <td>1.691306</td>\n",
       "      <td>3.899836</td>\n",
       "      <td>0.080415</td>\n",
       "      <td>1.173897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>-1.926267</td>\n",
       "      <td>-1.926490</td>\n",
       "      <td>-1.926630</td>\n",
       "      <td>-1.926703</td>\n",
       "      <td>-1.926764</td>\n",
       "      <td>-1.926822</td>\n",
       "      <td>-1.926857</td>\n",
       "      <td>-1.926886</td>\n",
       "      <td>-1.926903</td>\n",
       "      <td>-1.926923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397425</td>\n",
       "      <td>-0.383804</td>\n",
       "      <td>-0.346235</td>\n",
       "      <td>0.282216</td>\n",
       "      <td>0.392052</td>\n",
       "      <td>0.596976</td>\n",
       "      <td>1.691306</td>\n",
       "      <td>3.899836</td>\n",
       "      <td>0.080415</td>\n",
       "      <td>1.173897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        asks[0].price  asks[1].price  asks[2].price  asks[3].price  \\\n",
       "0           -1.715884      -1.716104      -1.716244      -1.716319   \n",
       "1           -1.715884      -1.716104      -1.716244      -1.716319   \n",
       "2           -1.715884      -1.716104      -1.716244      -1.716319   \n",
       "3           -1.715884      -1.716104      -1.716244      -1.716319   \n",
       "4           -1.715884      -1.716104      -1.716244      -1.716319   \n",
       "...               ...            ...            ...            ...   \n",
       "499995      -1.926267      -1.926490      -1.926630      -1.926703   \n",
       "499996      -1.926267      -1.926490      -1.926630      -1.926703   \n",
       "499997      -1.926267      -1.926490      -1.926630      -1.926703   \n",
       "499998      -1.926267      -1.926490      -1.926630      -1.926703   \n",
       "499999      -1.926267      -1.926490      -1.926630      -1.926703   \n",
       "\n",
       "        asks[4].price  asks[5].price  asks[6].price  asks[7].price  \\\n",
       "0           -1.716381      -1.716440      -1.716476      -1.716506   \n",
       "1           -1.716381      -1.716440      -1.716476      -1.716506   \n",
       "2           -1.716381      -1.716440      -1.716476      -1.716506   \n",
       "3           -1.716381      -1.716440      -1.716476      -1.716506   \n",
       "4           -1.716381      -1.716440      -1.716476      -1.716506   \n",
       "...               ...            ...            ...            ...   \n",
       "499995      -1.926764      -1.926822      -1.926857      -1.926886   \n",
       "499996      -1.926764      -1.926822      -1.926857      -1.926886   \n",
       "499997      -1.926764      -1.926822      -1.926857      -1.926886   \n",
       "499998      -1.926764      -1.926822      -1.926857      -1.926886   \n",
       "499999      -1.926764      -1.926822      -1.926857      -1.926886   \n",
       "\n",
       "        asks[8].price  asks[9].price  ...  bids[0].amount  bids[1].amount  \\\n",
       "0           -1.716525      -1.716545  ...        0.534043       -0.333162   \n",
       "1           -1.716525      -1.716545  ...        0.534043       -0.333162   \n",
       "2           -1.716525      -1.716545  ...        0.534043       -0.333162   \n",
       "3           -1.716525      -1.716545  ...        0.534043       -0.333162   \n",
       "4           -1.716525      -1.716545  ...        0.534043       -0.333162   \n",
       "...               ...            ...  ...             ...             ...   \n",
       "499995      -1.926903      -1.926923  ...       -0.433030       -0.383804   \n",
       "499996      -1.926903      -1.926923  ...       -0.397425       -0.383804   \n",
       "499997      -1.926903      -1.926923  ...       -0.397425       -0.383804   \n",
       "499998      -1.926903      -1.926923  ...       -0.397425       -0.383804   \n",
       "499999      -1.926903      -1.926923  ...       -0.397425       -0.383804   \n",
       "\n",
       "        bids[2].amount  bids[3].amount  bids[4].amount  bids[5].amount  \\\n",
       "0            -0.154572       -0.344645       -0.372711       -0.334547   \n",
       "1            -0.154572       -0.344645       -0.372711       -0.334547   \n",
       "2            -0.154572       -0.344645       -0.372711       -0.334547   \n",
       "3            -0.154572       -0.344645       -0.372711       -0.334547   \n",
       "4            -0.154572       -0.344645       -0.372711       -0.334547   \n",
       "...                ...             ...             ...             ...   \n",
       "499995       -0.346235        0.282216        0.353270        0.610318   \n",
       "499996       -0.346235        0.282216        0.353270        0.610318   \n",
       "499997       -0.346235        0.282216        0.392052        0.610318   \n",
       "499998       -0.346235        0.282216        0.392052        0.596976   \n",
       "499999       -0.346235        0.282216        0.392052        0.596976   \n",
       "\n",
       "        bids[6].amount  bids[7].amount  bids[8].amount  bids[9].amount  \n",
       "0            -0.406668       -0.004461       -0.002913       -0.446469  \n",
       "1            -0.406668       -0.004461       -0.002913       -0.446469  \n",
       "2            -0.406668       -0.004461       -0.002913        1.046836  \n",
       "3            -0.406668       -0.004461       -0.002913        1.047677  \n",
       "4            -0.406668       -0.004461       -0.002913        1.047677  \n",
       "...                ...             ...             ...             ...  \n",
       "499995        1.691306        3.899836        0.080415        1.173897  \n",
       "499996        1.691306        3.899836        0.080415        1.173897  \n",
       "499997        1.691306        3.899836        0.080415        1.173897  \n",
       "499998        1.691306        3.899836        0.080415        1.173897  \n",
       "499999        1.691306        3.899836        0.080415        1.173897  \n",
       "\n",
       "[500000 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "569bfdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(df, w = 100, a = 7e-6):\n",
    "    temp = df.copy()\n",
    "    temp[\"mid\"] = (temp['asks[0].price']*temp['bids[0].amount'] + temp['bids[0].price']*temp['asks[0].amount']) / (temp['bids[0].amount'] + temp['asks[0].amount'])\n",
    "    temp[\"mprev\"] = temp.mid.rolling(w).mean()\n",
    "    temp[\"maft\"] = temp.mprev.shift(-1*temp.mprev.isna().sum())\n",
    "    temp = temp.dropna()\n",
    "    temp[\"move\"] = (temp.maft - temp.mid)/temp.mid\n",
    "    temp[\"label\"] = (-(temp.move < -a).astype(int))  + (temp.move > a).astype(int)\n",
    "    return temp.iloc[:, :40], np.array(temp.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831a11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y  = get_x_y(d, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3647373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((499950, 40), (499950,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d034052f",
   "metadata": {},
   "source": [
    "#### X and y need reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d10ab83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  (499950, 40)\n",
      "after:  (499851, 100, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"before: \", x.shape)\n",
    "timestamp_per_sample = 100\n",
    "data_x = np.array(x)\n",
    "[N, P_x] = data_x.shape\n",
    "xt = np.zeros([(N-timestamp_per_sample+1), timestamp_per_sample, P_x])\n",
    "    \n",
    "for i in range(N-timestamp_per_sample+1):\n",
    "    xt[i] = data_x[i:(i+timestamp_per_sample), :]\n",
    "        \n",
    "xt = xt.reshape(xt.shape + (1,))\n",
    "print(\"after: \", xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33e4cb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  (499950,)\n",
      "after:  (499851, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"before: \", y.shape)\n",
    "yt = pd.get_dummies(y).values\n",
    "yt = yt[timestamp_per_sample -1:]\n",
    "print(\"after: \", yt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1485b8-77df-4c5f-89b3-ba2fe555151c",
   "metadata": {},
   "source": [
    "with open('x.npy', 'wb') as f:\n",
    "    np.save(f, xt)\n",
    "with open('y.npy', 'wb') as f:\n",
    "    np.save(f, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "327de4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((399880, 100, 40, 1), (99971, 100, 40, 1), (399880, 3), (99971, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xt,yt,test_size = 0.2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6502cf",
   "metadata": {},
   "source": [
    "### Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac907245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, MaxPooling2D, concatenate, LSTM, Reshape, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# import pandas_market_calendars as mcal\n",
    "\n",
    "def initiate_DeepLOB_model(lookback_timestep, feature_num, conv_filter_num, inception_num, LSTM_num, leaky_relu_alpha,\n",
    "                          loss, optimizer, metrics):\n",
    "    \n",
    "    input_tensor = Input(shape=(lookback_timestep, feature_num, 1))\n",
    "    \n",
    "    # Conv block1\n",
    "    print(input_tensor.shape)\n",
    "    conv_layer1 = Conv2D(conv_filter_num, (1,2), strides=(1, 2))(input_tensor)\n",
    "    print(conv_layer1.shape)\n",
    "    conv_layer1 =LeakyReLU(alpha=leaky_relu_alpha)(conv_layer1)\n",
    "    print(conv_layer1.shape)\n",
    "    conv_layer1 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer1)\n",
    "    conv_first1 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer1)\n",
    "    print(conv_layer1.shape)\n",
    "    conv_layer1 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer1)\n",
    "    conv_layer1 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer1)\n",
    "    print(conv_layer1.shape)\n",
    "\n",
    "    # Conv block2\n",
    "    conv_layer2 = Conv2D(conv_filter_num, (1,2), strides=(1, 2))(conv_layer1)\n",
    "    conv_layer2 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer2)\n",
    "    print(conv_layer2.shape)\n",
    "    conv_layer2 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer2)\n",
    "    conv_layer2 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer2)\n",
    "    print(conv_layer2.shape)\n",
    "    conv_layer2 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer2)\n",
    "    conv_layer2 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer2)\n",
    "    print(conv_layer2.shape)\n",
    "\n",
    "    # Conv block3\n",
    "    conv_layer3 = Conv2D(conv_filter_num, (1,10))(conv_layer2)\n",
    "    conv_layer3 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer3)\n",
    "    print(conv_layer3.shape)\n",
    "    conv_layer3 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer3)\n",
    "    conv_layer3 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer3)\n",
    "    print(conv_layer3.shape)\n",
    "    conv_layer3 = Conv2D(conv_filter_num, (4,1), padding='same')(conv_layer3)\n",
    "    conv_layer3 = LeakyReLU(alpha=leaky_relu_alpha)(conv_layer3)\n",
    "    print(conv_layer3.shape)\n",
    "    \n",
    "    # Inception module\n",
    "    inception_module1 = Conv2D(inception_num, (1,1), padding='same')(conv_layer3)\n",
    "    inception_module1 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module1)\n",
    "    print(inception_module1.shape)\n",
    "    inception_module1 = Conv2D(inception_num, (3,1), padding='same')(inception_module1)\n",
    "    inception_module1 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module1)\n",
    "    print(inception_module1.shape)\n",
    "\n",
    "    inception_module2 = Conv2D(inception_num, (1,1), padding='same')(conv_layer3)\n",
    "    inception_module2 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module2)\n",
    "    print(inception_module2.shape)\n",
    "    inception_module2 = Conv2D(inception_num, (5,1), padding='same')(inception_module2)\n",
    "    inception_module2 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module2)\n",
    "    print(inception_module2.shape)\n",
    "\n",
    "    inception_module3 = MaxPooling2D((3,1), strides=(1,1), padding='same')(conv_layer3)\n",
    "    print(inception_module3.shape)\n",
    "    inception_module3 = Conv2D(inception_num, (1,1), padding='same')(inception_module3)\n",
    "    print(inception_module3.shape)\n",
    "    inception_module3 = LeakyReLU(alpha=leaky_relu_alpha)(inception_module3)\n",
    "    print(inception_module3.shape)\n",
    "    \n",
    "    inception_module_final = concatenate([inception_module1, inception_module2, inception_module3], axis=3)\n",
    "    print(inception_module_final.shape)\n",
    "    inception_module_final = Reshape((inception_module_final.shape[1], inception_module_final.shape[3]))(inception_module_final)\n",
    "    print(inception_module_final.shape)\n",
    "\n",
    "    # LSTM\n",
    "    LSTM_output = LSTM(LSTM_num)(inception_module_final)\n",
    "    print(LSTM_output.shape)\n",
    "\n",
    "    # Fully Connected Layer with softmax activation function for output\n",
    "    model_output = Dense(3, activation='softmax')(LSTM_output)\n",
    "    print(model_output.shape)\n",
    "    \n",
    "    DeepLOB_model = Model(inputs=input_tensor, outputs= model_output)  \n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1)\n",
    "    \n",
    "    DeepLOB_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return DeepLOB_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4454cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 100, 40, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 17:45:33.615475: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-04 17:45:37.008038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30985 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 100, 20, 16)\n",
      "(None, 100, 20, 16)\n",
      "(None, 100, 20, 16)\n",
      "(None, 100, 20, 16)\n",
      "(None, 100, 10, 16)\n",
      "(None, 100, 10, 16)\n",
      "(None, 100, 10, 16)\n",
      "(None, 100, 1, 16)\n",
      "(None, 100, 1, 16)\n",
      "(None, 100, 1, 16)\n",
      "(None, 100, 1, 32)\n",
      "(None, 100, 1, 32)\n",
      "(None, 100, 1, 32)\n",
      "(None, 100, 1, 32)\n",
      "(None, 100, 1, 16)\n",
      "(None, 100, 1, 32)\n",
      "(None, 100, 1, 32)\n",
      "(None, 100, 1, 96)\n",
      "(None, 100, 96)\n",
      "(None, 64)\n",
      "(None, 3)\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 17:45:58.385602: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12497/12497 - 248s - loss: 0.8906 - accuracy: 0.6211 - val_loss: 0.7724 - val_accuracy: 0.6887 - 248s/epoch - 20ms/step\n",
      "Epoch 2/10000\n",
      "12497/12497 - 228s - loss: 0.7438 - accuracy: 0.6899 - val_loss: 0.7158 - val_accuracy: 0.6995 - 228s/epoch - 18ms/step\n",
      "Epoch 3/10000\n",
      "12497/12497 - 224s - loss: 0.7065 - accuracy: 0.7017 - val_loss: 0.6958 - val_accuracy: 0.7046 - 224s/epoch - 18ms/step\n",
      "Epoch 4/10000\n",
      "12497/12497 - 224s - loss: 0.6931 - accuracy: 0.7068 - val_loss: 0.6856 - val_accuracy: 0.7097 - 224s/epoch - 18ms/step\n",
      "Epoch 5/10000\n",
      "12497/12497 - 226s - loss: 0.6849 - accuracy: 0.7095 - val_loss: 0.6761 - val_accuracy: 0.7135 - 226s/epoch - 18ms/step\n",
      "Epoch 6/10000\n",
      "12497/12497 - 225s - loss: 0.6792 - accuracy: 0.7113 - val_loss: 0.6736 - val_accuracy: 0.7124 - 225s/epoch - 18ms/step\n",
      "Epoch 7/10000\n",
      "12497/12497 - 225s - loss: 0.6737 - accuracy: 0.7122 - val_loss: 0.6786 - val_accuracy: 0.7101 - 225s/epoch - 18ms/step\n",
      "Epoch 8/10000\n",
      "12497/12497 - 225s - loss: 0.6697 - accuracy: 0.7131 - val_loss: 0.6596 - val_accuracy: 0.7166 - 225s/epoch - 18ms/step\n",
      "Epoch 9/10000\n",
      "12497/12497 - 220s - loss: 0.6649 - accuracy: 0.7154 - val_loss: 0.6659 - val_accuracy: 0.7124 - 220s/epoch - 18ms/step\n",
      "Epoch 10/10000\n",
      "12497/12497 - 222s - loss: 0.6606 - accuracy: 0.7162 - val_loss: 0.6550 - val_accuracy: 0.7189 - 222s/epoch - 18ms/step\n",
      "Epoch 11/10000\n",
      "12497/12497 - 222s - loss: 0.6547 - accuracy: 0.7184 - val_loss: 0.6515 - val_accuracy: 0.7195 - 222s/epoch - 18ms/step\n",
      "Epoch 12/10000\n",
      "12497/12497 - 221s - loss: 0.6484 - accuracy: 0.7202 - val_loss: 0.6463 - val_accuracy: 0.7232 - 221s/epoch - 18ms/step\n",
      "Epoch 13/10000\n",
      "12497/12497 - 220s - loss: 0.6480 - accuracy: 0.7209 - val_loss: 0.6395 - val_accuracy: 0.7266 - 220s/epoch - 18ms/step\n",
      "Epoch 14/10000\n",
      "12497/12497 - 213s - loss: 0.6404 - accuracy: 0.7238 - val_loss: 0.6442 - val_accuracy: 0.7196 - 213s/epoch - 17ms/step\n",
      "Epoch 15/10000\n",
      "12497/12497 - 217s - loss: 0.6375 - accuracy: 0.7248 - val_loss: 0.6305 - val_accuracy: 0.7281 - 217s/epoch - 17ms/step\n",
      "Epoch 16/10000\n",
      "12497/12497 - 218s - loss: 0.6333 - accuracy: 0.7269 - val_loss: 0.6387 - val_accuracy: 0.7266 - 218s/epoch - 17ms/step\n",
      "Epoch 17/10000\n",
      "12497/12497 - 219s - loss: 0.6286 - accuracy: 0.7290 - val_loss: 0.6276 - val_accuracy: 0.7304 - 219s/epoch - 18ms/step\n",
      "Epoch 18/10000\n",
      "12497/12497 - 220s - loss: 0.6249 - accuracy: 0.7297 - val_loss: 0.6189 - val_accuracy: 0.7336 - 220s/epoch - 18ms/step\n",
      "Epoch 19/10000\n",
      "12497/12497 - 218s - loss: 0.6225 - accuracy: 0.7312 - val_loss: 0.6232 - val_accuracy: 0.7275 - 218s/epoch - 17ms/step\n",
      "Epoch 20/10000\n",
      "12497/12497 - 219s - loss: 0.6151 - accuracy: 0.7342 - val_loss: 0.6220 - val_accuracy: 0.7337 - 219s/epoch - 18ms/step\n",
      "Epoch 21/10000\n",
      "12497/12497 - 222s - loss: 0.6142 - accuracy: 0.7344 - val_loss: 0.6242 - val_accuracy: 0.7287 - 222s/epoch - 18ms/step\n",
      "Epoch 22/10000\n",
      "12497/12497 - 219s - loss: 0.6102 - accuracy: 0.7367 - val_loss: 0.6107 - val_accuracy: 0.7349 - 219s/epoch - 17ms/step\n",
      "Epoch 23/10000\n",
      "12497/12497 - 219s - loss: 0.6077 - accuracy: 0.7380 - val_loss: 0.6082 - val_accuracy: 0.7388 - 219s/epoch - 17ms/step\n",
      "Epoch 24/10000\n",
      "12497/12497 - 218s - loss: 0.6025 - accuracy: 0.7399 - val_loss: 0.6068 - val_accuracy: 0.7390 - 218s/epoch - 17ms/step\n",
      "Epoch 25/10000\n",
      "12497/12497 - 218s - loss: 0.5978 - accuracy: 0.7417 - val_loss: 0.6191 - val_accuracy: 0.7341 - 218s/epoch - 17ms/step\n",
      "Epoch 26/10000\n",
      "12497/12497 - 218s - loss: 0.5926 - accuracy: 0.7441 - val_loss: 0.5820 - val_accuracy: 0.7483 - 218s/epoch - 17ms/step\n",
      "Epoch 27/10000\n",
      "12497/12497 - 220s - loss: 0.5917 - accuracy: 0.7438 - val_loss: 0.5950 - val_accuracy: 0.7454 - 220s/epoch - 18ms/step\n",
      "Epoch 28/10000\n",
      "12497/12497 - 221s - loss: 0.5863 - accuracy: 0.7465 - val_loss: 0.5813 - val_accuracy: 0.7488 - 221s/epoch - 18ms/step\n",
      "Epoch 29/10000\n"
     ]
    }
   ],
   "source": [
    "#Input param\n",
    "lookback_timestep = 100\n",
    "feature_num = 40\n",
    "\n",
    "#Conv param\n",
    "conv_filter_num = 16\n",
    "\n",
    "#Inception module param\n",
    "inception_num = 32\n",
    "\n",
    "#LSTM param\n",
    "LSTM_num = 64\n",
    "\n",
    "#Activation param\n",
    "leaky_relu_alpha = 0.01\n",
    "\n",
    "#Training params\n",
    "loss = 'categorical_crossentropy'\n",
    "learning_rate = 0.01\n",
    "adam_epsilon = 1\n",
    "optimizer = Adam(learning_rate=learning_rate, epsilon=1)\n",
    "batch_size = 32\n",
    "\n",
    "#Training stopping Criteria\n",
    "metrics = ['accuracy']\n",
    "#stop training when validation accuracy does not improve for 20 epochs\n",
    "stop_epoch_num = 20\n",
    "\n",
    "#max epoch num is not specified in paper, use an arbitrary large number 10000\n",
    "num_epoch = 10000\n",
    "\n",
    "DeepLOB_model = initiate_DeepLOB_model(lookback_timestep, feature_num, conv_filter_num, inception_num, LSTM_num, leaky_relu_alpha,\n",
    "                          loss, optimizer, metrics)\n",
    "\n",
    "# definte the training stop criteria (no new max validation accuracy in 20 consecutive epochs)\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience = stop_epoch_num, verbose=1)\n",
    "history = DeepLOB_model.fit(X_train, y_train, epochs=num_epoch, batch_size=batch_size, verbose=2, validation_data=(X_test, y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2908ca57",
   "metadata": {},
   "source": [
    "#### Data prep and training require massive amounts of memory and processing power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
